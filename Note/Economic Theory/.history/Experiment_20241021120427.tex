\documentclass[11pt]{elegantbook}
\usepackage{graphicx}
%\usepackage{float}
\definecolor{structurecolor}{RGB}{40,58,129}
\linespread{1.6}
\setlength{\footskip}{20pt}
\setlength{\parindent}{0pt}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\elegantnewtheorem{proof}{Proof}{}{Proof}
\elegantnewtheorem{claim}{Claim}{prostyle}{Claim}
\DeclareMathOperator{\col}{col}
\title{Psychology and Economics}
\author{Wenxiao Yang}
\institute{Haas School of Business, University of California Berkeley}
\date{2024}
\setcounter{tocdepth}{2}
\extrainfo{All models are wrong, but some are useful.}

\cover{cover.png}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}


\bibliographystyle{apalike_three}

\begin{document}
\maketitle

\frontmatter
\tableofcontents

\mainmatter



\chapter{Becker-DeGroot-Marschak Mechanism}
\cite{karni1987preference} showed that the BDM is not incentive compatible when the object being valued is a lottery. The BDM can elicit the certainty equivalents of given lotteries if and only if the respondent's preferences can be represented by expected utility functional.


\chapter{Choice in Context}
\section{\cite{simonson1989choice}: Choice Based on Reasons: The Case of Attraction and Compromise Effects}
Two effects about consumers' choices are introduced:
\begin{enumerate}
    \item \textbf{Attraction Effect} (asymmetric dominance effect): When an asymmetrically dominated or relatively inferior alternative is added to a set, the attractiveness and choice probability of the dominating alternative increase.
    \item \textbf{Compromise Effect}: An alternative would tend to gain market share when it becomes a compromise or middle option in the set.
\end{enumerate}
This paper use the framework that decision makers make the choice that is supported by the best overall reasons to analyze these attraction and compromise effects.

It’s good that this paper aims to explain both the attraction and compromise effects through a single framework. However, the mechanism and explanation the paper proposes for these two effects is not fully validated by the experiments.

Decision-makers take into account others’ evaluations and make choices based on their expectations of the evaluators’ preferences. One reason for choosing middle alternatives may be the uncertainty surrounding these preferences. But what if the evaluators’ preferences are clearly defined and extreme? I would propose an experiment where participants are told their decisions will be evaluated by evaluators with a common, extreme preference. According to the theory presented in the paper, participants would then be more likely to choose an extreme alternative that aligns with the evaluators’ preferences, rather than opting for a middle option. This could help further test and refine the proposed mechanism and explanation.


\section{\cite{simonson1992choice}: Choice in Context: Tradeoff Contrast and Extremeness Aversion}
This paper takes a context-based approach to explain tradeoff contrast and extremeness aversion, which also offers a new mechanism for understanding the attraction and compromise effects described in earlier work. By framing decision-making through the lens of reference dependence and loss aversion, it provides a powerful alternative to the traditional value maximization framework in classical economic theory, where such psychological influences are often overlooked.

This perspective is especially useful for firms in designing product lines and attributes, as it highlights how the context in which products are presented can significantly influence consumer preferences. However, while the theory is compelling, it would be even more impactful if we could quantify these context effects and the degree of loss aversion. Such quantification could broaden the practical applications.

In the future (or perhaps this is already done), it would be beneficial to develop formal models that integrate this framework into economic theory, enabling its use in quantitative analysis. A formalization of context effects and loss aversion within an economic model would bridge the gap between behavioral insights and actionable, data-driven decision-making.

\section{\cite{evangelidis2018asymmetric}: The Asymmetric Impact of Context on Advantaged Versus Disadvantaged Options}
To explain this, the authors propose a hierarchical decision-making framework:
\begin{enumerate}
    \item Firstly, decision makers examine whether one of the alternatives dominates all the others in the set. If there is no such alternative,
    \item decision makers then search for the next easiest solution - an option that allows them to avoid considering the subjective value of an attribute and making detailed analyses of trade-offs. If they still cannot find such an option,
    \item they determine which of the two attributes is most important to them and select the option that scores the highest on that attribute.
\end{enumerate}


This paper examines the asymmetric impact of context effects, specifically showing that such effects are more likely to occur when a new option similar to the disadvantaged alternative (the weaker or lower-share option) is introduced into a binary choice set. This finding builds on previous literature, offering a fresh perspective on how context influences decision-making, particularly in relation to asymmetric dominance and extremeness aversion.

One of the key contributions of this paper is the proposal of a hierarchical decision-making process, which highlights the complexity behind consumer choices. Unlike prior research that tends to assume a simpler decision-making process of trade-offs, this approach emphasizes that individuals may use different strategies depending on the choice set. By recognizing this, the paper suggests that incorporating hierarchical models of decision-making or information acquisition provide new insights for future research, both in quantitative and behavioral studies.

From a practical standpoint, the paper’s insights are valuable for firms designing product lines or attributes. However, while understanding the decision-making process is crucial, companies typically base their product designs on consumer preferences. Combining insights on consumer preferences with the decision-making process could significantly enhance the applicability of these findings in practice. Unfortunately, this paper does not explore the interaction between these two factors, leaving an important and interesting direction for future research.


\section{\cite{evangelidis2023upscaling}: The Upscaling Effect: How the Decision Context Influences Tradeoffs between Desirability and Feasibility}
This paper introduces a novel context effect, termed the upscaling effect, wherein the introduction of a symmetrically dominated decoy option increases the choice share of the high-desirability (HD) option rather than the high-feasibility (HF) option. The authors propose a two-stage decision-making process to explain this phenomenon, suggesting that consumers first identify the HD option as a promising alternative and then seek justifications to support this choice, particularly when a decoy is introduced.
\begin{enumerate}
    \item Individuals first look for “the alternative that most naturally can be seen as dominant over the others.” This paper proposes that a high-desirability (i.e., HD) option is more likely to be identified as a promising alternative compared to a high-feasibility (i.e., HF) alternative.
    \item Secondly, consumers will seek to accumulate evidence that supports choice of the promising alternative.
    \subitem Generally, if consumers can identify a reason that allows them to justify choosing the HD option, they will terminate the decision process by selecting the said option. If they cannot identify strong enough reasons supporting the choice of the HD option, consumers may subsequently look for reasons supporting the choice of the HF alternative or defer choice.
\end{enumerate}

This theory builds on the choice based on reasons framework, similar to the approach used in prior research. It’s a valuable perspective for understanding decision-making processes, but I wonder whether the reference dependence and loss aversion framework from another key paper could also explain this effect. For instance, a simple explanation could be that introducing a dominated decoy lowers individuals’ reference points for both desirability and feasibility. Consequently, the loss aversion associated with the lower feasibility of the HD option diminishes, making the HD option more appealing and gaining a higher market share.

Beyond this alternative explanation, it would be interesting to examine the upscaling effect in non-binary choice sets, which could have more practical implications. Extending the study of this effect beyond binary sets may offer valuable insights into more complex real-world business applications.


\chapter{Overthinking}
\section{\cite{wilson1993introspecting}: Introspecting About Reasons Can Reduce Post-Choice Satisfaction}
This paper presents a theory suggesting that people assign different weights to the attributes of alternatives when making choices, and introspecting about reasons can disrupt this process. The theory posits that when people analyze their reasons, they tend to focus on attributes that are easier to verbalize and that seem like plausible reasons, even if they aren’t the most important factors in their initial evaluations. This shift in focus can lead to a suboptimal weighting of attributes, altering preferences. Over time, as the initial weighting scheme reasserts itself, individuals may regret their choices.

The theory is intriguing, but several points remain unclear. For instance, what are the specific attributes that become underweighted in the suboptimal weighting scheme? Additionally, this theory doesn’t align well with other models of decision-making, such as those we recently studied, which rely on reason-based choice rules. In this theory, reasons are seen as potentially disruptive to decision-making, whereas other frameworks view them as integral to the process. Is there a theoretical approach that can reconcile these differing perspectives on the role of reasons in decision-making?

\section{\cite{dijksterhuis2006making}: On Making the Right Choice: The Deliberation-Without-Attention Effect}
There are some evidence suggests that unconscious thought can sometimes lead to good choices. Unconscious Thought Theory (UTT) is formulated in \cite{dijksterhuis2006theory}, which gives the strengths and weaknesses of conscious thought and unconscious thought:
\begin{enumerate}
    \item Conscious thought is rule-based and very precise.
    \item Because of the low capacity of consciousness, conscious thought is less suitable for very complex issues. (It has been shown that during unconscious thought (deliberation without attention), large amounts of information can be integrated into an evaluative summary judgment.)
\end{enumerate}

This theory is compelling, yet it does not consider how decision-makers apply decision rules, particularly how they manage the limited capacity of conscious thought. Moreover, UTT separates decision-making from the information acquisition process. Are decision-makers relying on unconscious thought able to gather as much information as those using conscious thought?

\section{\cite{lee2009search}: Stronger Emotional Response Yield Consistent Preferences}
Previous research has established the dual-system model, where both the emotional and cognitive systems contribute to decision-making. This paper hypothesizes that a greater reliance on the emotional system can result in more consistent preferences across individuals. In the experiments, the authors attempt to manipulate the use of the emotional system in various ways. However, I find the experimental controls somewhat lacking in reliability. The use of the term “emotional” does not seem entirely precise or convincing in relation to the methods employed in the experiments.


\section{\cite{pham2012feeling}: The Emotional Oracle Effect}
This paper explores the concept of the “Emotional Oracle Effect,” demonstrating that individuals who have a higher trust in their feelings are better able to predict the outcomes of future events compared to those with lower trust in their emotions. Across eight studies, participants predicted various outcomes, such as political elections, movie box-office results, stock market trends, and even the weather. The results indicate that trusting one’s feelings provides access to a “privileged window” of accumulated, often unconscious, knowledge, allowing for more accurate judgments. However, the effect was only present when individuals had sufficient background knowledge about the domain and dissipated when outcomes became inherently unpredictable. While the study highlights the value of emotional reliance in prediction tasks, it also raises questions about the limits of this effect, particularly in domains where rational, rule-based thinking is typically prioritized. Overall, the findings challenge traditional views that emotions hinder decision-making and suggest that feelings can, under certain conditions, be a reliable guide for future predictions.



\chapter{Overconfidence}
\section{\cite{moore2008trouble}: Theory of Confidence}
Overconfidence is defined in three distinct way:
\begin{enumerate}
    \item \textit{Overestimation}: the overestimation of one's actual ability, performance, level of control, or chance of success.
    \item \textit{Overplacement / Better-than-average}:  people believe themselves to be better than others, such as when a majority of people rate themselves better than the median.
    \item \textit{Overprecision}: excessive certainty regarding the accuracy of one's beliefs.
\end{enumerate}

There are three most common problems identified in overconfidence:
\begin{enumerate}
    \item The Confounding of Overestimation and Overprecision.
    \item Underconfidence.
    \item Inconsistency Between Overestimation and Overplacement.
\end{enumerate}

This article proposes \textit{a theory of confidence}: After experiencing a task, people often have imperfect information about their own performances but even worse information about the performances of others. As a result, people's post-task estimates of themselves are regressive, and their estimates of others are even more regressive. Consequently, when performance is exceptionally high, people will underestimate their own performances, underestimate others even more so, and thus believe that they are better than others. When performance is low, people will overestimate themselves, overestimate others even more so, and thus believe that they are worse than others.

\subsection*{Formal Model}
People hold a subjective probability distribution (SPD) of their own score and an SPD of others' scores over the range of possible outcomes on any task.
\begin{enumerate}
    \item \textit{Overestimation} occurs when a person's SPD of his or her own score has a mean that is greater than the person's actual score on the task.
    \item \textit{Overplacement} occurs when a person's SPD of his or her own score has a mean that is greater than the mean of the SPD of others' scores and this belief is not justified by differences in actual scores between self and others.
    \item \textit{Overprecision}  describes an SPD that is narrower (has lower variance) than reality suggests it ought to be.
\end{enumerate}

Suppose there is a quiz taker $i$ who has a belief about her likely score, which is denoted by a random variable $X_i$. $X_i$ is assumed to be decomposed into two components:
\begin{equation}
    \begin{aligned}
        X_i=S+L_i,
    \end{aligned}
    \nonumber
\end{equation}
where $S$ is the global average score on the quiz and $L_i$ is the idiosyncratic performance on the quiz of the quiz taker.

The $i$'s prior beliefs about $S$ and $L_i$ are assumed to be $\mathcal{N}(m_S,v_S)$ and $\mathcal{N}(0,v_L)$, respectively. Then, the prior belief about $X_i$ is $\mathcal{N}(m_S,v_S+v_L)$.

We consider the four points in time:
\begin{enumerate}
    \item \textit{Prior stage}: before the quiz, when the individual has no useful information about anyone's performance.
    \item \textit{Interim stage}: after taking the quiz but before learning her own score or the score of anyone.\\
    We think of $i$ as having observed a signal of her score $y_i$, which is assumed to be a realization of a random variable $Y_i=X_i+E_i$, where $E_i\sim \mathcal{N}(0,v_E)$.
    \item \textit{Posterior stage}: after learning her own score, but not the scores of others.
    \item \textit{Resolution}: after learning the scores of others.
\end{enumerate}

In the \textit{interim stage}, the expected score of $i$ given $y_i$ is
\begin{equation}
    \begin{aligned}
        \mathbb{E}[X_i\mid y_i]=\alpha m_S +(1-\alpha)y_i, \textnormal{ where }\alpha=\frac{v_L+v_E}{v_S+v_L+v_E}
    \end{aligned}
    \nonumber
\end{equation}
\paragraph*{Overconfidence} Given $y_i$ is unbiased, we have
\begin{equation}
    \begin{aligned}
        \mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]=\alpha m_S +(1-\alpha)x_i
    \end{aligned}
    \nonumber
\end{equation}
where $x_i$ is the true score $x_i$.

Therefore, if the quiz is easier than expected ($x_i>m_S$), we have $m_S<\mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]<x_i$. That is, we observe underestimation. If the quiz is harder than expected ($x_i<m_S$), we have $m_S>\mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]>x_i$. That is, we observe overestimation.

\paragraph*{Overplacement}
Suppose that individual $i$ is told her true score $x_i$ and is asked report her expectation about individual $j$'s score.

To infer $X_j=S+L_j$, we study the inference for the overall average score on the quiz $S$ because $\mathbb{E}[X_j\mid x_i]=\mathbb{E}[S\mid x_i]$. Using Bayes's law, $i$'s expectation of $S$ given $x_i$ is
\begin{equation}
    \begin{aligned}
        \mathbb{E}[S\mid x_i]=\beta m_S + (1-\beta)x_i, \textnormal{ where }\beta=\frac{v_L}{v_S+v_L}
    \end{aligned}
    \nonumber
\end{equation}
Therefore, $i$ exhibits an overplacement ($m_S<\mathbb{E}[X_j\mid x_i]<x_i$) if her own score is above the prior expected average (because the quiz was easier than expected), and exhibits an underplacement ($m_S>\mathbb{E}[X_j\mid x_i]>x_i$) if her own score is below the prior expected average (because the quiz was harder than expected).

\paragraph*{Overprecision}
Estimations made by people whose signals are less informative about their true scores ought to be more regressive and ought therefore to display greater underestimation on easy tasks, as well as more overestimation on difficult tasks.



\chapter{Wisdom of Crowds}
\section{\cite{mannes2014wisdom}: The Wisdom of Select Crowds}
Previous works show that neither relying on the average opinion nor a single expert is a robust strategy for accurate judgment. This paper demonstrates that averaging the opinions of a selected group of the most knowledgeable judges leads to more accurate and robust judgments. Moreover, this strategy appeals to those distrustful of relying on crowd-based methods.

This is an interesting paper, but while it provides evidence for a strategy that is more robust and accurate than the traditional wisdom of crowds, the conclusions are not particularly groundbreaking. The idea of selectively averaging opinions based on expertise can be easily derived from basic statistical principles and seems more like common sense than an innovative discovery. However, it is still good to have empirical evidence to strengthen this point.


\section{\cite{simmons2011intuitive}: Intuitive Biases in Choice versus Estimation}
Previous research shows that bettors tend to exhibit an intuitive bias, leading them to believe that the superior team (i.e., the favorite) is more likely to win. This bias causes them to underweight point spreads, even when explicitly informed that the spreads are biased. Furthermore, this bias not only persists but strengthens over time, a phenomenon explained by attribution theory: bettors attribute winning predictions to their own skill and intuition, while attributing losses to bad luck. This paper demonstrates that a different elicitation method can eliminate this judgment bias.

This paper provides an interesting contribution by highlighting how behavioral biases can distort elicited judgments and the importance of employing the correct elicitation method. These findings can also offer valuable insights for economic research. In many mechanism design problems that aim to elicit truthful reports, behavioral biases play a crucial role but are often overlooked.


\section{\cite{gaertig2021psychology}: The Psychology of Second Guesses: Implications for the Wisdom of the Inner Crowd}
Previous research has shown that a small improvement can be achieved by averaging two guesses from the same individual, known as the “wisdom of the inner crowd.” This paper demonstrates that the effectiveness of this phenomenon depends on the processes individuals use to make their second guesses. For example, asking whether the first guess was “too high” or “too low” before the second guess tends to weaken the wisdom of the inner crowd effect in most cases.

This is an interesting paper, as it provides empirical evidence for a behavior that could be inferred from statistical principles. It is valuable to see experimental data confirming such intuitive ideas, emphasizing the importance of how the second guess is elicited to maintain the benefits of the wisdom of the inner crowd.


\chapter{Emotions / Regret}
\section{\cite{frijda2017laws}: The Laws of Emotion}
The law of emotions is illustrated by ``the law of situational meaning'': emotions arise in response to the meaning structures of given situations. (In other words, meaning structures are lawfully connected to forms of action readiness.)

The law of situational meaning has a necessary complement in ``the law of concern'': Emotions arise in response to events that are important to the individual's goals, motives, or concerns. Moreover, the events to be appraised as real and the intensity of emotions corresponds to the degree to which they are perceived as real (Law of Apparent Reality).

The emotions obey ``the law of change (Habituation / Comparative Feeling)'': emotions are elicited by the actual or expected change. This law follows 1. ``The law of hedonic asymmetry'': the pleasure disappears with continuous satisfaction while the pain persists with continuous adverse conditions; 2. ``The law of conservation of emotional momentum'':  emotional events retain their power to elicit emotions indefinitely, unless counteracted by repetitive exposures that permit extinction or habituation, to the extent that these are possible.

The emotion response follows ``the law of closure'': Emotions tend to be closed to judgments of relativity of impact and to the requirements of goals other than their own. At the same time, every emotional impulse elicits a secondary impulse that tends to modify it in view of its possible consequences, which is called ``the law of care for consequence.'' Human also tends to minimize negative emotional load when the situation can be viewed in alternative ways, which is called ``the law of the lightest load.''

(\textbf{Summary}: This article explains how emotions follow a set of “laws” that govern their emergence and regulation. The law of situational meaning suggests that emotions arise from how we interpret events, with different situations triggering different emotions. The law of concern states that emotions are only triggered by events that matter to our personal goals or concerns. The intensity of these emotions is determined by the law of apparent reality, meaning the more real an event feels, the stronger the emotional response. Emotions are more likely to be triggered by changes rather than ongoing states, which is captured by the law of change. According to the law of hedonic asymmetry, pleasure fades with continuous satisfaction, but pain can persist in difficult conditions. The law of emotional momentum explains that emotions do not fade over time unless repeatedly exposed to the same event. Emotions often focus intensely on the present, as described by the law of closure, but are moderated by the law of care for consequence, which adjusts emotional responses to avoid negative outcomes. Lastly, the law of the lightest load and law of the greatest gain suggest that people tend to interpret situations in ways that minimize emotional distress or maximize emotional benefit. This is an interesting introduction to emotions and I have no comment on it.)

\section{\cite{zeelenberg2007theory}: A Theory of Regret Regulation 1.0}
Regret is a negative, self-blaming emotion that arises when people realize or imagine that their situation could have been better had they made different choices. It is a comparison-based emotion influenced by how one evaluates past decisions and their consequences. People are motivated to regulate regret in order to maximize immediate outcomes and improve future decision-making. Individual differences in the tendency to experience regret are linked to how much one compares and strives to maximize outcomes. Regret can occur both in response to past decisions (retrospective regret) and anticipated future choices (prospective regret), particularly when decisions are difficult, important, and when outcomes of both chosen and unchosen options will soon be known. Regret can stem from actions and inactions, with more justifiable decisions generally reducing the intensity of regret. Although regret aversion—avoiding regret—and risk aversion are distinct, they both independently influence decisions. For instance, in situations where participants could choose between a risky or safe option, those expecting feedback on the safe option were more likely to choose it. However, I question whether risk aversion is truly independent of regret aversion, as uncertainty also exists in regret decisions (the “regret lottery”), so how can we be sure that risk aversion does not influence regret aversion as well?


\section{\cite{zeelenberg2007theory}: Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty}
In the most stylized form, the model can be summarized as
\begin{equation}
    \begin{aligned}
        m_{ij}^k=c_{ij}+R(c_{ij}-c_{kj})
    \end{aligned}
    \nonumber
\end{equation}
The model presented in the equation is a stylized way of formalizing regret aversion, and it provides an interesting perspective. However, from a mathematical standpoint, the model appears quite similar to the concept of reference dependence. This raises the question: can regret aversion be explained by reference dependence? Specifically, if both regret and reference dependence involve comparisons between actual outcomes and potential alternatives, is regret aversion simply a specific form of reference-dependent decision-making?


\chapter{Uncertainty}
\section{\cite{fox1995ambiguity}: Ambiguity Aversion and Comparative Ignorance}
This paper proposes the \textit{comparative ignorance} hypothesis that ambiguity aversion is produced by a comparison with less ambiguous events or with more knowledgeable individuals. That is, when people compare two events about which they have different levels of knowledge, the contrast makes the less familiar bet less attractive or the more familiar bet more attractive.


\section{\cite{gneezy2006uncertainty}: The uncertainty effect: When a risky prospect is valued less than its worst possible outcome}
This paper proposes an \textit{uncertainty effect}. That is, under some cases, individuals value a risky prospect less than its worst possible outcome.

In one of its experiments (between-subject tests), the average WTP for the \$50 gift certificate was significantly higher than that for the lottery offering an even chance at a \$50 or \$100 gift certificate.

The present research suggests that there are choice situations in which decision-makers discount lotteries for uncertainty in a manner that is difficult to reconcile with standard models.

This research is based on the use of a different currency than the pricing currency or the comparison alternative. Since the internality axiom is transparent and compelling with using fiat currencies as prizes, how important the loss of acuity induced by the uncertainty of translating the prize to the cognitive demand? Is there any research that discuss the relationship between the loss of acuity and the uncertainty effect?

Note that this uncertainty effect is also called the \textit{Direct risk aversion}, which is checked by \ref{}


\section{\cite{mazar2017retailing}: When Retailing and Las Vegas Meet: Probabilistic Free Price Promotions}
This research shows that, for planned purchases, a probabilistic free price promotion is preferred to a sure price promotion of equal expected monetary value.  This preference is not driven by an attraction to a zero price, an aversion to transaction cost, or novelty, but rather primarily due to a diminishing sensitivity to the prices.


\section{\cite{gaertig2018and}: Why (and When) Are Uncertain Price Promotions More Effective Than Equivalent Sure Discounts?}
“Peanuts Effect” has found that risk-aversion decreases with decreasing monetary amounts, such that at very small stakes people are relatively more likely to be risk seeking than risk averse. Based on the ``peanuts effect'', this paper shows that, probabilistic price promotions are more attractive than equivalent sure discounts only when those sure discounts seem trivial. Note that the same amount may be seen as large or small depending on how it is framed, and that framing can in turn influence risk preferences.



\bibliography{ref_BE}




\end{document}