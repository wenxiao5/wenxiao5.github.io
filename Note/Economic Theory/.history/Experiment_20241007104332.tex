\documentclass[11pt]{elegantbook}
\usepackage{graphicx}
%\usepackage{float}
\definecolor{structurecolor}{RGB}{40,58,129}
\linespread{1.6}
\setlength{\footskip}{20pt}
\setlength{\parindent}{0pt}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\elegantnewtheorem{proof}{Proof}{}{Proof}
\elegantnewtheorem{claim}{Claim}{prostyle}{Claim}
\DeclareMathOperator{\col}{col}
\title{Psychology and Economics}
\author{Wenxiao Yang}
\institute{Haas School of Business, University of California Berkeley}
\date{2024}
\setcounter{tocdepth}{2}
\extrainfo{All models are wrong, but some are useful.}

\cover{cover.png}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}


\bibliographystyle{apalike_three}

\begin{document}
\maketitle

\frontmatter
\tableofcontents

\mainmatter



\chapter{Becker-DeGroot-Marschak Mechanism}
\cite{karni1987preference} showed that the BDM is not incentive compatible when the object being valued is a lottery. The BDM can elicit the certainty equivalents of given lotteries if and only if the respondent's preferences can be represented by expected utility functional.


\chapter{Choice in Context}
\section{\cite{simonson1989choice}: Choice Based on Reasons: The Case of Attraction and Compromise Effects}
Two effects about consumers' choices are introduced:
\begin{enumerate}
    \item \textbf{Attraction Effect} (asymmetric dominance effect): When an asymmetrically dominated or relatively inferior alternative is added to a set, the attractiveness and choice probability of the dominating alternative increase.
    \item \textbf{Compromise Effect}: An alternative would tend to gain market share when it becomes a compromise or middle option in the set.
\end{enumerate}
This paper use the framework that decision makers make the choice that is supported by the best overall reasons to analyze these attraction and compromise effects.

It’s good that this paper aims to explain both the attraction and compromise effects through a single framework. However, the mechanism and explanation the paper proposes for these two effects is not fully validated by the experiments.

Decision-makers take into account others’ evaluations and make choices based on their expectations of the evaluators’ preferences. One reason for choosing middle alternatives may be the uncertainty surrounding these preferences. But what if the evaluators’ preferences are clearly defined and extreme? I would propose an experiment where participants are told their decisions will be evaluated by evaluators with a common, extreme preference. According to the theory presented in the paper, participants would then be more likely to choose an extreme alternative that aligns with the evaluators’ preferences, rather than opting for a middle option. This could help further test and refine the proposed mechanism and explanation.


\section{\cite{simonson1992choice}: Choice in Context: Tradeoff Contrast and Extremeness Aversion}
This paper takes a context-based approach to explain tradeoff contrast and extremeness aversion, which also offers a new mechanism for understanding the attraction and compromise effects described in earlier work. By framing decision-making through the lens of reference dependence and loss aversion, it provides a powerful alternative to the traditional value maximization framework in classical economic theory, where such psychological influences are often overlooked.

This perspective is especially useful for firms in designing product lines and attributes, as it highlights how the context in which products are presented can significantly influence consumer preferences. However, while the theory is compelling, it would be even more impactful if we could quantify these context effects and the degree of loss aversion. Such quantification could broaden the practical applications.

In the future (or perhaps this is already done), it would be beneficial to develop formal models that integrate this framework into economic theory, enabling its use in quantitative analysis. A formalization of context effects and loss aversion within an economic model would bridge the gap between behavioral insights and actionable, data-driven decision-making.

\section{\cite{evangelidis2018asymmetric}: The Asymmetric Impact of Context on Advantaged Versus Disadvantaged Options}
To explain this, the authors propose a hierarchical decision-making framework:
\begin{enumerate}
    \item Firstly, decision makers examine whether one of the alternatives dominates all the others in the set. If there is no such alternative,
    \item decision makers then search for the next easiest solution - an option that allows them to avoid considering the subjective value of an attribute and making detailed analyses of trade-offs. If they still cannot find such an option,
    \item they determine which of the two attributes is most important to them and select the option that scores the highest on that attribute.
\end{enumerate}


This paper examines the asymmetric impact of context effects, specifically showing that such effects are more likely to occur when a new option similar to the disadvantaged alternative (the weaker or lower-share option) is introduced into a binary choice set. This finding builds on previous literature, offering a fresh perspective on how context influences decision-making, particularly in relation to asymmetric dominance and extremeness aversion.

One of the key contributions of this paper is the proposal of a hierarchical decision-making process, which highlights the complexity behind consumer choices. Unlike prior research that tends to assume a simpler decision-making process of trade-offs, this approach emphasizes that individuals may use different strategies depending on the choice set. By recognizing this, the paper suggests that incorporating hierarchical models of decision-making or information acquisition provide new insights for future research, both in quantitative and behavioral studies.

From a practical standpoint, the paper’s insights are valuable for firms designing product lines or attributes. However, while understanding the decision-making process is crucial, companies typically base their product designs on consumer preferences. Combining insights on consumer preferences with the decision-making process could significantly enhance the applicability of these findings in practice. Unfortunately, this paper does not explore the interaction between these two factors, leaving an important and interesting direction for future research.


\section{\cite{evangelidis2023upscaling}: The Upscaling Effect: How the Decision Context Influences Tradeoffs between Desirability and Feasibility}
This paper introduces a novel context effect, termed the upscaling effect, wherein the introduction of a symmetrically dominated decoy option increases the choice share of the high-desirability (HD) option rather than the high-feasibility (HF) option. The authors propose a two-stage decision-making process to explain this phenomenon, suggesting that consumers first identify the HD option as a promising alternative and then seek justifications to support this choice, particularly when a decoy is introduced.
\begin{enumerate}
    \item Individuals first look for “the alternative that most naturally can be seen as dominant over the others.” This paper proposes that a high-desirability (i.e., HD) option is more likely to be identified as a promising alternative compared to a high-feasibility (i.e., HF) alternative.
    \item Secondly, consumers will seek to accumulate evidence that supports choice of the promising alternative.
    \subitem Generally, if consumers can identify a reason that allows them to justify choosing the HD option, they will terminate the decision process by selecting the said option. If they cannot identify strong enough reasons supporting the choice of the HD option, consumers may subsequently look for reasons supporting the choice of the HF alternative or defer choice.
\end{enumerate}

This theory builds on the choice based on reasons framework, similar to the approach used in prior research. It’s a valuable perspective for understanding decision-making processes, but I wonder whether the reference dependence and loss aversion framework from another key paper could also explain this effect. For instance, a simple explanation could be that introducing a dominated decoy lowers individuals’ reference points for both desirability and feasibility. Consequently, the loss aversion associated with the lower feasibility of the HD option diminishes, making the HD option more appealing and gaining a higher market share.

Beyond this alternative explanation, it would be interesting to examine the upscaling effect in non-binary choice sets, which could have more practical implications. Extending the study of this effect beyond binary sets may offer valuable insights into more complex real-world business applications.


\chapter{Overthinking}
\section{\cite{wilson1993introspecting}: Introspecting About Reasons Can Reduce Post-Choice Satisfaction}
This paper presents a theory suggesting that people assign different weights to the attributes of alternatives when making choices, and introspecting about reasons can disrupt this process. The theory posits that when people analyze their reasons, they tend to focus on attributes that are easier to verbalize and that seem like plausible reasons, even if they aren’t the most important factors in their initial evaluations. This shift in focus can lead to a suboptimal weighting of attributes, altering preferences. Over time, as the initial weighting scheme reasserts itself, individuals may regret their choices.

The theory is intriguing, but several points remain unclear. For instance, what are the specific attributes that become underweighted in the suboptimal weighting scheme? Additionally, this theory doesn’t align well with other models of decision-making, such as those we recently studied, which rely on reason-based choice rules. In this theory, reasons are seen as potentially disruptive to decision-making, whereas other frameworks view them as integral to the process. Is there a theoretical approach that can reconcile these differing perspectives on the role of reasons in decision-making?

\section{\cite{dijksterhuis2006making}: On Making the Right Choice: The Deliberation-Without-Attention Effect}
There are some evidence suggests that unconscious thought can sometimes lead to good choices. Unconscious Thought Theory (UTT) is formulated in \cite{dijksterhuis2006theory}, which gives the strengths and weaknesses of conscious thought and unconscious thought:
\begin{enumerate}
    \item Conscious thought is rule-based and very precise.
    \item Because of the low capacity of consciousness, conscious thought is less suitable for very complex issues. (It has been shown that during unconscious thought (deliberation without attention), large amounts of information can be integrated into an evaluative summary judgment.)
\end{enumerate}

This theory is compelling, yet it does not consider how decision-makers apply decision rules, particularly how they manage the limited capacity of conscious thought. Moreover, UTT separates decision-making from the information acquisition process. Are decision-makers relying on unconscious thought able to gather as much information as those using conscious thought?

\section{\cite{lee2009search}: Stronger Emotional Response Yield Consistent Preferences}
Previous research has established the dual-system model, where both the emotional and cognitive systems contribute to decision-making. This paper hypothesizes that a greater reliance on the emotional system can result in more consistent preferences across individuals. In the experiments, the authors attempt to manipulate the use of the emotional system in various ways. However, I find the experimental controls somewhat lacking in reliability. The use of the term “emotional” does not seem entirely precise or convincing in relation to the methods employed in the experiments.


\section{\cite{pham2012feeling}: The Emotional Oracle Effect}
This paper explores the concept of the “Emotional Oracle Effect,” demonstrating that individuals who have a higher trust in their feelings are better able to predict the outcomes of future events compared to those with lower trust in their emotions. Across eight studies, participants predicted various outcomes, such as political elections, movie box-office results, stock market trends, and even the weather. The results indicate that trusting one’s feelings provides access to a “privileged window” of accumulated, often unconscious, knowledge, allowing for more accurate judgments. However, the effect was only present when individuals had sufficient background knowledge about the domain and dissipated when outcomes became inherently unpredictable. While the study highlights the value of emotional reliance in prediction tasks, it also raises questions about the limits of this effect, particularly in domains where rational, rule-based thinking is typically prioritized. Overall, the findings challenge traditional views that emotions hinder decision-making and suggest that feelings can, under certain conditions, be a reliable guide for future predictions.



\chapter{Overconfidence}
\section{\cite{moore2008trouble}: Theory of Confidence}
Overconfidence is defined in three distinct way:
\begin{enumerate}
    \item \textit{Overestimation}: the overestimation of one's actual ability, performance, level of control, or chance of success.
    \item \textit{Overplacement / Better-than-average}:  people believe themselves to be better than others, such as when a majority of people rate themselves better than the median.
    \item \textit{Overprecision}: excessive certainty regarding the accuracy of one's beliefs.
\end{enumerate}

There are three most common problems identified in overconfidence:
\begin{enumerate}
    \item The Confounding of Overestimation and Overprecision.
    \item Underconfidence.
    \item Inconsistency Between Overestimation and Overplacement.
\end{enumerate}

This article proposes \textit{a theory of confidence}: After experiencing a task, people often have imperfect information about their own performances but even worse information about the performances of others. As a result, people's post-task estimates of themselves are regressive, and their estimates of others are even more regressive. Consequently, when performance is exceptionally high, people will underestimate their own performances, underestimate others even more so, and thus believe that they are better than others. When performance is low, people will overestimate themselves, overestimate others even more so, and thus believe that they are worse than others.

\subsection*{Formal Model}
People hold a subjective probability distribution (SPD) of their own score and an SPD of others' scores over the range of possible outcomes on any task.
\begin{enumerate}
    \item \textit{Overestimation} occurs when a person's SPD of his or her own score has a mean that is greater than the person's actual score on the task.
    \item \textit{Overplacement} occurs when a person's SPD of his or her own score has a mean that is greater than the mean of the SPD of others' scores and this belief is not justified by differences in actual scores between self and others.
    \item \textit{Overprecision}  describes an SPD that is narrower (has lower variance) than reality suggests it ought to be.
\end{enumerate}

Suppose there is a quiz taker $i$ who has a belief about her likely score, which is denoted by a random variable $X_i$. $X_i$ is assumed to be decomposed into two components:
\begin{equation}
    \begin{aligned}
        X_i=S+L_i,
    \end{aligned}
    \nonumber
\end{equation}
where $S$ is the global average score on the quiz and $L_i$ is the idiosyncratic performance on the quiz of the quiz taker.

The $i$'s prior beliefs about $S$ and $L_i$ are assumed to be $\mathcal{N}(m_S,v_S)$ and $\mathcal{N}(0,v_L)$, respectively. Then, the prior belief about $X_i$ is $\mathcal{N}(m_S,v_S+v_L)$.

We consider the four points in time:
\begin{enumerate}
    \item \textit{Prior stage}: before the quiz, when the individual has no useful information about anyone's performance.
    \item \textit{Interim stage}: after taking the quiz but before learning her own score or the score of anyone.\\
    We think of $i$ as having observed a signal of her score $y_i$, which is assumed to be a realization of a random variable $Y_i=X_i+E_i$, where $E_i\sim \mathcal{N}(0,v_E)$.
    \item \textit{Posterior stage}: after learning her own score, but not the scores of others.
    \item \textit{Resolution}: after learning the scores of others.
\end{enumerate}

In the \textit{interim stage}, the expected score of $i$ given $y_i$ is
\begin{equation}
    \begin{aligned}
        \mathbb{E}[X_i\mid y_i]=\alpha m_S +(1-\alpha)y_i, \textnormal{ where }\alpha=\frac{v_L+v_E}{v_S+v_L+v_E}
    \end{aligned}
    \nonumber
\end{equation}
\paragraph*{Overconfidence} Given $y_i$ is unbiased, we have
\begin{equation}
    \begin{aligned}
        \mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]=\alpha m_S +(1-\alpha)x_i
    \end{aligned}
    \nonumber
\end{equation}
where $x_i$ is the true score $x_i$.

Therefore, if the quiz is easier than expected ($x_i>m_S$), we have $m_S<\mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]<x_i$. That is, we observe underestimation. If the quiz is harder than expected ($x_i<m_S$), we have $m_S>\mathbb{E}_{Y_i\mid x_i}[\mathbb{E}[X_i\mid y_i]]>x_i$. That is, we observe overestimation.

\paragraph*{Overplacement}
Suppose that individual $i$ is told her true score $x_i$ and is asked report her expectation about individual $j$'s score.

To infer $X_j=S+L_j$, we study the inference for the overall average score on the quiz $S$ because $\mathbb{E}[X_j\mid x_i]=\mathbb{E}[S\mid x_i]$. Using Bayes's law, $i$'s expectation of $S$ given $x_i$ is
\begin{equation}
    \begin{aligned}
        \mathbb{E}[S\mid x_i]=\beta m_S + (1-\beta)x_i, \textnormal{ where }\beta=\frac{v_L}{v_S+v_L}
    \end{aligned}
    \nonumber
\end{equation}
Therefore, $i$ exhibits an overplacement ($m_S<\mathbb{E}[X_j\mid x_i]<x_i$) if her own score is above the prior expected average (because the quiz was easier than expected), and exhibits an underplacement ($m_S>\mathbb{E}[X_j\mid x_i]>x_i$) if her own score is below the prior expected average (because the quiz was harder than expected).

\paragraph*{Overprecision}
Estimations made by people whose signals are less informative about their true scores ought to be more regressive and ought therefore to display greater underestimation on easy tasks, as well as more overestimation on difficult tasks.



\chapter{Wisdom of Crowds}
\section{\cite{mannes2014wisdom}: The Wisdom of Select Crowds}
Previous works show that neither relying on the average opinion nor a single expert is a robust strategy for accurate judgment. This paper demonstrates that averaging the opinions of a selected group of the most knowledgeable judges leads to more accurate and robust judgments. Moreover, this strategy appeals to those distrustful of relying on crowd-based methods.

This is an interesting paper, but while it provides evidence for a strategy that is more robust and accurate than the traditional wisdom of crowds, the conclusions are not particularly groundbreaking. The idea of selectively averaging opinions based on expertise can be easily derived from basic statistical principles and seems more like common sense than an innovative discovery. However, it is still good to have empirical evidence to strengthen this point.


\section{\cite{simmons2011intuitive}: Intuitive Biases in Choice versus Estimation}





























\bibliography{ref_BE}




\end{document}