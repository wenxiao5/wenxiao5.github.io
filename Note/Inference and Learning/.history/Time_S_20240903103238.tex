\documentclass[11pt]{elegantbook}
\usepackage{graphicx}
%\usepackage{float}
\definecolor{structurecolor}{RGB}{40,58,129}
\linespread{1.6}
\setlength{\footskip}{20pt}
\setlength{\parindent}{0pt}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\elegantnewtheorem{proof}{Proof}{}{Proof}
\elegantnewtheorem{claim}{Claim}{prostyle}{Claim}
\DeclareMathOperator{\col}{col}
\title{Time Series}
\author{Wenxiao Yang}
\institute{Haas School of Business, University of California Berkeley}
\date{2024}
\setcounter{tocdepth}{2}
\extrainfo{All models are wrong, but some are useful.}

\cover{cover.png}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}

\addbibresource[location=local]{reference.bib} % bib

\begin{document}
\maketitle

\frontmatter
\tableofcontents

\mainmatter

\chapter{Time Series Analysis}
\section{Goals and Terminology}
\subsection*{Goals and Challenge}
\textbf{Data} in time series is denoted by
\begin{equation}
    \begin{aligned}
        \{\underbrace{y_t}_{n\times 1}:1\leq t\leq T\}
    \end{aligned}
    \nonumber
\end{equation}
%Some fundamental assumptions are needed for statistics.
\begin{assumption}
    Each $y_t$ is the realization of some random vector $Y_t$.
\end{assumption}
The \textbf{objective} is to provide data-based answers to questions about the distribution of $\{Y_t:1\leq t\leq T\}$.

The \textbf{challenge} we face is $Y_1,Y_2,...,Y_T$ are \textit{not necessarily independent}. Time series analysis gives the models and methods that can accommodate dependence.

\subsection*{Terminology}
Some terminologies we need to know:
\begin{definition}[Stochastic Process]
    A \textbf{stochastic process} is a collection $\{Y_t:t\in\mathcal{T}\}$ of random variables/vectors (defined on the same probability space).
    \begin{enumerate}
        \item $\{Y_t:t\in\mathcal{T}\}$ is \textbf{discrete time process} if $\mathcal{T}=\{1,...,T\}$ or $\mathcal{T}=\mathbb{N}=\{1,2,...\}$ or $\mathcal{T}=\mathbb{Z}=\{...,-1,0,1,...\}$.
        \item $\{Y_t:t\in\mathcal{T}\}$ is \textbf{continuous time process} if $\mathcal{T}=[0,1]$ or $\mathcal{T}=\mathbb{R}_+$ or $\mathcal{T}=\mathbb{R}$.
    \end{enumerate}
\end{definition}
Observed data $Y_t$ is a realization of a discrete time process with $\mathcal{T}=\{1,...,T\}$.

\begin{definition}[Strictly Stationary (Discrete and Scalar Process)]
    A scalar\footnote{i.e., $Y_t$ is $1\times 1$} process $\{Y_t:t\in \mathbb{Z}\}$ is \textbf{strictly stationary} \textit{if and only if}
    \begin{equation}
        \begin{aligned}
            \left(Y_t,...,Y_{t+k}\right)\underbrace{\sim}_\textnormal{``is distributed as''} \left(Y_0,...,Y_{k}\right),\ \forall t\in \mathbb{Z},k\geq 0
        \end{aligned}
        \nonumber
    \end{equation}
\end{definition}
\begin{note}
    \begin{enumerate}
        \item If $Y_t\sim i.i.d.$, then $\{Y_t:t\in \mathbb{Z}\}$ is strictly stationary.
        \item If $\{Y_t:t\in \mathbb{Z}\}$ is strictly stationary, then $Y_t$ are identically distributed (i.e., ``marginal stationary'').
        \begin{example}[ Strictly Stationary and Dependent]
            A constant process that $...=Y_{-1}=Y_0=Y_1=...$ is strictly stationary.
        \end{example}
    \end{enumerate}
    All these above hold for strictly stationary vector process.
\end{note}

\begin{lemma}[Property of Strictly Stationary]
    If $\{Y_t:t\in \mathbb{Z}\}$ is strictly stationary with $\mathbb{E}[Y_t^2]<\infty$ ($\forall t$), then
    \begin{enumerate}
        \item Same Expectation:
        \begin{equation}
            \begin{aligned}
                \mathbb{E}[Y_t]=\mu,\ \forall t \textnormal{ (for some constant $\mu$)}
            \end{aligned}
            \label{s}
            \tag{*}
        \end{equation}
        \item Covariance only depends on time length:
        \begin{equation}
            \begin{aligned}
                \textnormal{Cov}(Y_t,Y_{t-j})=\gamma(j),\ \forall t,j \textnormal{ (for some function $\gamma(\cdot)$)}
            \end{aligned}
            \label{ss}
            \tag{**}
        \end{equation}
    \end{enumerate}
\end{lemma}

A subset of strictly stationary processes that has second moment (i.e., $\mathbb{E}[Y_t^2]<\infty$) can be defined as \textbf{covariance stationary}.
\begin{definition}[Covariance Stationary]
    A process $\{Y_t:t\in \mathbb{Z}\}$ is \textbf{covariance stationary} \textit{iff} $\mathbb{E}[Y_t^2]<\infty$ ($\forall t$) and it satisfies \eqref{s} and \eqref{ss}.
\end{definition}
\begin{note}
    Not every strictly stationary process is covariance stationary. (e.g., if it does not have second moment).
\end{note}


\begin{definition}
    $\gamma(\cdot)$ in \eqref{ss} is called \textbf{autocovariance function} of $\{Y_t:t\in \mathbb{Z}\}$.\\
    The \textbf{autocorrelation function} is
    \begin{equation}
        \begin{aligned}
            \rho(j)=\textnormal{Corr}(Y_t,Y_{t-j})=\frac{Cov(Y_t,Y_{t-j})}{\sqrt{\textnormal{Var}(Y_t)\textnormal{Var}(Y_{t-j})}}
        \end{aligned}
        \nonumber
    \end{equation}
\end{definition}





































\end{document}