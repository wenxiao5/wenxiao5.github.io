\documentclass[11pt]{elegantbook}
\usepackage{graphicx}
%\usepackage{float}
\definecolor{structurecolor}{RGB}{40,58,129}
\linespread{1.6}
\setlength{\footskip}{20pt}
\setlength{\parindent}{0pt}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\elegantnewtheorem{proof}{Proof}{}{Proof}
\elegantnewtheorem{claim}{Claim}{prostyle}{Claim}
\DeclareMathOperator{\col}{col}
\title{Causal Inference}
\author{Wenxiao Yang}
\institute{Haas School of Business, University of California Berkeley}
\date{2025}
\setcounter{tocdepth}{2}
\extrainfo{All models are wrong, but some are useful.}

\cover{cover.png}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}


\bibliographystyle{apalike_three}

\begin{document}
\maketitle

\frontmatter
\tableofcontents

\mainmatter



\chapter{Causal Inference}
The fundamental problem of causal inference:
\begin{enumerate}[(a).]
    \item Never see the same person treated and untreated
    \item Missing data problem
    \item "Solve" by finding a comparison group
\end{enumerate}

\begin{definition}[Notations and Estimands]
    \normalfont
    \begin{enumerate}[$\circ$]
        \item Treatment: $T\in\{0,1\}$
        \item Potential Outcome with treatment $Y(1), Y(0)$
        \item Other Variable $X$
        \item Individual Treatment Effect (ITE) $= Y_i(1)-Y_i(0)$
        \item Conditional Average Treatment Effect (CATE) $=\mathbb{E}[Y(1)-Y(0)|X=x]:=\tau(x)$
        \item Average Treatment Effect (ATE) $=\mathbb{E}[Y(1)-Y(0)]:=\tau$
        \item Average Treatment Effects on Treated (ATT) $=\mathbb{E}[Y(1)-Y(0)\mid T=1]$
    \end{enumerate}
\end{definition}


\subsection*{Difference in Means}
\begin{equation}
    \begin{aligned}
        \hat{\tau}=\bar{Y}_1-\bar{Y}_0=\frac{1}{n_1}\sum_{i=1}^n Y_i T_i - \frac{1}{n_0}\sum_{i=1}^n Y_i(1-T_i)
    \end{aligned}
    \nonumber
\end{equation}

By the Law of Large Numbers,
\begin{equation}
    \begin{aligned}
        \lim_{n \rightarrow \infty}\frac{1}{n_1}\sum_{i=1}^n Y_i T_i&=\lim_{n \rightarrow \infty}\frac{n}{n_i}\frac{1}{n}\sum_{i=1}^n Y_i T_i\\
        &=\left(P[T=1]\right)^{-1} \mathbb{E}[YT]\\
        &= \left(P[T=1]\right)^{-1}\mathbb{E}[YT\mid T=1]P[T=1]\\
        &=\mathbb{E}[YT\mid T=1]\\
        \bar{Y}_1 &\stackrel{P}{\longrightarrow} \mathbb{E}[YT\mid T=1]
    \end{aligned}
    \nonumber
\end{equation}

\subsubsection*{Causal Effect}
\begin{assumption}\quad
    \begin{enumerate}[(1).]
        \item SUTVA: Only your treatment matters;
        \item Consistency: Observed outcome matches treatment "assignment": $Y=TY(1)+(1-T)Y(0)$.
    \end{enumerate}
\end{assumption}

Only yields $\hat{\tau}=\bar{Y}_1-\bar{Y}_0\stackrel{P}{\longrightarrow} \mathbb{E}[Y(1)\mid T=1]-\mathbb{E}[Y(0)\mid T=0]$

\begin{equation}
    \begin{aligned}
        &\mathbb{E}[Y(1)\mid T=1]-\mathbb{E}[Y(0)\mid T=0]\\
        =&\underbrace{\mathbb{E}[Y(1)\mid T=1]-\mathbb{E}[Y(0)\mid T=1]}_{\textnormal{ATT}}+\underbrace{\mathbb{E}[Y(0)\mid T=1]-\mathbb{E}[Y(0)\mid T=0]}_{\textnormal{selection bias}}\\
    \end{aligned}
    \nonumber
\end{equation}
To get the ATT (eliminate the selection bias), we need exclusion/independence: Randomization.


Assume $Y(t)=\mu(t)+\epsilon_t$ (SUTVA). Consider the consistency assumption:
\begin{equation}
    \begin{aligned}
        Y&=TY(1)+(1-T)Y(0)\\
        &=Y(0)+T(Y(1)-Y(0))\\
        &=\underbrace{\mu_0}_\alpha+T\underbrace{(\mu_1-\mu_0)}_{\beta^T}+\underbrace{\epsilon_0+T(\epsilon_1-\epsilon_0)}_{\epsilon}
    \end{aligned}
    \nonumber
\end{equation}

Consider the covariate between $T$ and $X$. Why important?

\begin{equation}
    \begin{aligned}
        &\mathbb{E}[Y|X=1,T=1]-\mathbb{E}[Y|X=1,T=0]\\
        =& \underbrace{\mathbb{E}[Y(1)|X(1)=1]-\mathbb{E}[Y(0)|X(1)=1]}_{\textnormal{ATE}|X(1)=1} + \underbrace{\mathbb{E}[Y(0)|X(1)=1]-\mathbb{E}[Y(0)|X(0)=1]}_{\textnormal{selection bias}}\\
    \end{aligned}
    \nonumber
\end{equation}


$Y(t)=\mu(t,X)+\epsilon_t$. Then,
\begin{equation}
    \begin{aligned}
        Y&=Y(1)T+Y(0)(1-T)\\
        &=\underbrace{\mu(0,X)}_{\alpha(X)} + T\underbrace{(\mu_1(X)-\mu_0(X))}_{\beta(X)}+\epsilon
    \end{aligned}
    \nonumber
\end{equation}



\chapter{STAT 256}
\section{Lecture Zero: Causal Inference vs Association}{Amanda Coston}

\subsection{Causal Inference on the Effect of Red Wine on Health}\label{sec:intro}

\subsection{Is red wine good for heart health?}
For many years consensus held that red wine improved cardiovascular health. The evidence behind this was largely from studies on people of drinking age that compared the health outcomes of those who self-reported that they drank wine to those who self-reported that they did not. Findings under such a design showed that people who drink  red wine have better cardiovascular outcomes than those who don't drink alcohol.

What are potential problems with this study design? You may be thinking that people who drink wine systematically differ from those who don't in ways that matter for health outcomes. In fact, sociologist Kaye Middleton Fillmore showed that the statistical significance of these findings hinged on the inclusion of \emph{previous} drinkers in the ``non-drinkers" category. That is, some people who said they did not drink red wine previously drank alcohol. Problematically, a common reason these people gave up alcohol was poor health. Therefore the definition of  ``non-drinkers" selected for people who had poorer health outcomes. Fillmore showed that redefining ``non-drinkers" to be ``never-drinkers" eliminated any supposed advantage of drinking wine.

The debate here was one of causal inference -- looking at the cause and effect of red wine on health.

For more details, see \cite{fillmore2007moderate}.

\subsection{Syllabus}

See course syllabi here: \href{https://stat156.berkeley.edu/fall-2024/syllabus.html}{https://stat156.berkeley.edu/fall-2024/syllabus.html}.

\subsection{Association vs Causation}

Association is the focus of much of statistics but in causal inference our focus is, of course, on causation! As a starting point, we will today consider common measures of association and discuss why they may not capture causation. In the next lecture we will see causal analogues of these measures.
aaa
We first consider the setting where the outcome $Y$ and treatment $Z$ are both binary. 

\begin{definition}[Risk Difference]
    The associative risk difference (RD) is $E[Y \mid Z = 1] - E[Y \mid Z = 0]$.
\end{definition}


\begin{definition}[Risk Ratio]
    The associative risk ratio (RR) is $P[Y =1 \mid Z = 1]/P[Y =1 \mid Z = 0]$.
\end{definition}

\begin{definition}[Odds Ratio]
    The associative odds ratio (OR) is $\frac{P[Y =1 \mid Z = 1]}{P[Y =0 \mid Z = 1]}/\frac{P[Y=1 \mid Z = 0]}{P[Y=0 \mid Z = 0]}$.
\end{definition}

Which measure one chooses depends on their particular setting -- what question they are interested in and what data they have available (odds ratios can be estimated in with outcome-dependent sampling whereas the risk difference and risk ratio generally cannot). The measures are related to each other as follows:

\begin{enumerate}
    \item $Z \perp Y  \Longleftrightarrow \mathrm{RD} = 0 \Longleftrightarrow \mathrm{RR} = 1 \Longleftrightarrow \mathrm{OR} = 1$
    \item $\mathrm{RD} > 0 \Longleftrightarrow \mathrm{RR} > 1 \Longleftrightarrow \mathrm{OR} > 1$ assuming all conditional probabilities are non-zero.
    \item $\mathrm{RR} \approx \mathrm{OR}$ when $P(Y=1)$ is small.
\end{enumerate}

Next we consider measures of association that can accommodate non-binary outcomes. 

\subsection{Correlation and linear regression}
Suppose we are now interested in the outcome blood pressure as a measure of cardiovascular health. A natural starting point is to model the relationship between blood pressure ($Y$) and whether one drinks red wine ($Z$) as 

\begin{align*}
    Y = \beta Z + \alpha + \epsilon
\end{align*}

where $E[\epsilon] = 0 $ and $E[\epsilon Z ] = 0$.

Recall that we can relate $\beta$ to the Pearson correlation coefficient $\rho$ as follows

\begin{align*}
    \beta = \rho \frac{\mathrm{var}(Z)}{\mathrm{var}(Y)}.
\end{align*}

The coefficient $\beta$ describes the change in $Y$ associated with whether one drinks red wine. More generally, the coefficient $\beta$ describes the change in $Y$ associated with one unit increase in $Z$.
Sometimes people refer to $\beta$ as the ``effect" of $Z$ on $Y$ but this is generally misleading (without further assumptions). We have simply modeled an associative relationship; we can't claim anything causal yet! Next time we will introduce a new language, potential outcomes, so that we can make causal claims.


\section{Lecture One: Potential Outcomes Framework}{Aryan Shafat, Frederik Stihler, Mika Lee (Revisions)}

\subsection{Review of last lecture}\label{sec:review}
Review of Risk Difference, Risk Ratio and Odds Ratio for setting where the outcome $Y$ and treatment $Z$ are both binary. (See lecture notes of Lecture 0 for details)

Explanation of the last equivalence in the following statement:
\begin{center}
$\mathrm{RD} > 0 \Longleftrightarrow \mathrm{RR} > 1 \Longleftrightarrow \mathrm{OR} > 1$ assuming all conditional probabilities are non-zero
\end{center}

We know that:

\begin{center}
    $\mathbb{P}[Y = 1 \mid Z = 1] + \mathbb{P}[Y = 0 \mid Z = 1] = 1$ and
    $\mathbb{P}[Y = 1 \mid Z = 0] +$ $\mathbb{P}[Y = 0 \mid Z = 0] = 1$. 
\end{center}    
    $\mathrm{RR} > 1$ implies that $\mathbb{P}[Y = 1 \mid Z = 1] > \mathbb{P}[Y = 1 \mid Z = 0]$, and hence $\mathbb{P}[Y = 0 \mid Z = 0] > \mathbb{P}[Y = 0 \mid Z = 1]$. This leads us to $\mathrm{OR} > 1$.

\subsection{Potential Outcome Framework}\label{sec:pof}

\subsubsection{Types of questions we are interested in}

\begin{enumerate}
    \item Does journaling reduce the risk of depression?
    \item Do personalized AI tutors improve a student's grade?
    \item Does smoking cigarettes cause cancer?
\end{enumerate}

We can summarize these questions in the following table: \par
\begin{center}
\begin{tabular}{ccc}
  \hline
  & \textbf{$Z$} & \textbf{$Y$} \\
  \hline
  1 & Journal & Depression \\
  \hline
  2 & AI tutor & Grade  \\
  \hline
  3 & Cigarettes & Cancer  \\
  \hline
\end{tabular}
\end{center}

For all the examples, we want to form a causal estimand using potential outcomes. The potential outcome framework was developed by \citet{neyman1923} in 1923 over one hundred years ago and later revitalized and repopularized by \citet{rubin1980} in 1980. 

\subsubsection{Potential Outcomes}

We are interested in potential (hypothetical) outcomes when we are thinking about causal questions.

\begin{definition}[Potential Outcome]
    The potential outcome Y is a function of a particular treatment value $Y(Z=z)$.
\end{definition}

E.g. $Y(Z=1) = Y(1)$ (the potential outcome under the intervention that assigns treatment) vs. $Y(Z=0) = Y(0)$ (the potential outcome under the intervention that assigns no treatment).

In our particular examples, these quantities are represented by the following hypothetical questions: \par

(1) Would someone have depression if they journalled $\approx Y(1)$ \\
(2) Would a  student get a particular grade if they had an AI tutor $\approx Y(1)$ \\
(3) Would someone get cancer if they smoked cigarettes $\approx Y(1)$

\subsubsection{Causal Estimands}

Next we define the causal versions of our measures of association (called  causal estimands).

\begin{definition}[Causal Risk Difference]
    The causal risk difference (on a population level) is $E[Y(1) - Y(0)]$.
\end{definition}

\begin{definition}[Causal Risk Ratio]
    The causal risk ratio is $\frac{E[Y(1)]}{E[Y(0)]} = \frac{P(Y(1) = 1)}{P(Y(0) = 1)}$.
\end{definition}

\begin{definition}[Causal Odds Ratio]
    The causal odds ratio is $\frac{P(Y(1) = 1)}{P(Y(1) = 0)}/\frac{P(Y(0) = 1)}{P(Y(0) = 0)} = \\ 
    \frac{E[Y(1)]}{E[1-Y(1)]}/\frac{E[Y(0)]}{E[1-Y(0)]}$.
\end{definition}

\subsubsection{Hidden Assumptions}

As mentioned, \citet{rubin1980} repopularized this framework by clarifying some important hidden assumptions:

\begin{assumption}[Consistency]
The treatment levels are well-defined (there are no other versions of the treatment).
\end{assumption}

\begin{assumption}[No Interference]
The treatment assigned to other units does not affect the potential outcomes for unit $i$ (no spillover).
\end{assumption}

These 2 assumptions are called \textbf{Stable Unit Treatment Value Assumption (SUTVA).}

For example, our 3rd question/example about cigarette smoking violates both assumptions.

The question isn't well-defined (does smoking entail  smoking 1 cigarette a day or smoking a whole pack a day) and thus violates Assumption 1.

It also violates Assumption 2, through non-smokers who might end up passively smoking by being around smokers.

\subsection{Causal Estimands}
Causal Effects are functions of potential outcomes. For example, the causal risk difference is essentially the 'average treatment effect'.

\begin{itemize}
    \item Unit 'i' has 2 potential outcomes: $Y_i$(1) and $Y_i$(0)
\end{itemize}

\begin{itemize}
    \item \textbf{Individualized treatment effect:} $Y_i$(1) - $Y_i$(0)
\end{itemize}

\textbf{Fundamental Problem of Causal Inference (1986 Holland):}
Never observe both potential outcomes.

\subsubsection{Add a time-element}
We could include a time element - write into our personal journal/smoke a cigarette/receive treatment one day and then go without treatment the next day, to see the 'causal effect' of the treatment.

However, the effect of the treatment might be long-lasting. Thus, one could 'experience'/observe their causal effects even on the days without treatment. Additionally, say for a time-period of 2 days, we actually end up having 4 potential outcomes:

\begin{itemize}
    \item $Y_{i, day 1}$(1) vs $Y_{i, day 1}$(0)
\end{itemize}

\begin{itemize}
    \item $Y_{i, day 2}$(1) vs $Y_{i, day 2}$(0)
\end{itemize}


Going back to the potential outcomes framework, we basically end up 'observing' one of the potential outcomes framework.

\begin{itemize}
    \item The factual/observed outcome is, $Y_i = 
\begin{cases}
Y_i(1) & \text{if } Z_i = 1 \\
Y_i(0) & \text{if } Z_i = 0
\end{cases}
$ 
\end{itemize}

Equivalently, 

$Y_i = Z_i*Y_i(1) + (1-Z_i)*Y_i(0)$

\begin{itemize}

\item The (unobserved) counterfactual, or missing potential outcome is given by:

$Y_i^{\text{mis}} = Z_i*Y_i(0) + (1-Z_i)*Y_i(1)$

\end{itemize}

\subsection{Simpson's Paradox}
Based on the class poll, we saw that the effect of the hint wasn't that strong. There was a confounding variable (row number) that was dampening the effect of the hint (since most of the hints were given to people in the rows at the back). This was attributed to \textbf{Simpson's Paradox}, which might have made it seem like the hints had an \textbf{effect reversal} (as if those who got the hints actually ended up doing worse on the poll).

This is mathematically shown as:
$\mathbb{P}(Y=1|Z=0) > \mathbb{P}(Y=1|Z=1)$. However, we can easily counter this by conditioning on the confounding variable (X):

\begin{center}
    $\mathbb{P}(Y=1|Z=0, X=x) < \mathbb{P}(Y=1|Z=1, X=x) \quad  \forall x \in X $
\end{center}

\subsubsection{Sources of the paradox:}
\begin{itemize}
    \item Confounding variables/factors
    \item Non-collapsibility
\end{itemize}





\bibliography{ref}

\end{document}