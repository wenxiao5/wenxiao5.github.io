\documentclass[11pt]{elegantbook}
\definecolor{structurecolor}{RGB}{40,58,129}
\linespread{1.6}
\setlength{\footskip}{20pt}
\setlength{\parindent}{0pt}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\elegantnewtheorem{proof}{Proof}{}{Proof}
\elegantnewtheorem{claim}{Claim}{prostyle}{Claim}
\DeclareMathOperator{\col}{col}
\title{\textbf{Unsupervised Learning}}
\author{Wenxiao Yang}
\institute{Department of Mathematics, University of Illinois at Urbana-Champaign}
\date{}
\setcounter{tocdepth}{2}
\cover{cover.jpg}
\extrainfo{All models are wrong, but some are useful.}

% modify the color in the middle of titlepage
\definecolor{customcolor}{RGB}{32,178,170}
\colorlet{coverlinecolor}{customcolor}
\usepackage{cprotect}

\addbibresource[location=local]{reference.bib} % bib

\begin{document}

\maketitle
\frontmatter
\tableofcontents
\mainmatter

\chapter{Clustering}
General Goal of \textbf{Clustering Algorithm}:
\begin{enumerate}[$\circ$]
    \item the "similarity" of the objects in the same cluster is \underline{maximized} while
    \item the "similarity" of objects in different clusters is \underline{minimized}.
\end{enumerate}

\begin{definition}
    For a given set of objects $V = \{x_1, x_2, ... , x_m\}$, we call a \textbf{cluster $\mathbf{S_k}$} a subset of these objects, and we call a \textbf{clustering} the set of all $K$ clusters $\mathbf{\{S_1 ,S_2 , ... , S_k\}}$.
\end{definition}
\begin{example}
    Clustering of $\{x_1,x_2,x_3,x_4\}$: (1). $\{\{x_1,x_3\},\{x_2,x_4\}\}$; (2). $\{\{x_1,x_3\},\{x_1,x_2,x_4\}\}$; (3). $\{\{x_3\},\{x_2,x_4\}\}$.
\end{example}

\section{K-Means}
\subsection{Clustering Optimization Problem}
\begin{enumerate}
    \item \textbf{Input:}
    \subitem Desired number of clusters (ex: $K=3$)
    \subitem Dataset of $m$ objects $X=\{\vec{x}_1,\vec{x}_2,...,\vec{x}_m\}$, where each object $\vec{x}_i=(x_{i1},x_{i2},...\vec{x}_{in})$ has $n$ numerical attributes. (We can also think of $X$ as being an $m\times n$ matrix $X_{m\times n}$.)
    \item \textbf{Goal of k-Means:}
    \subitem Out of all possible clusterings of $\{S_1 ,S_2 , ... , S_K\}$ with $K$ clusters that can be made from the $m$ objects in $X$, find the optimal clustering $\{S_1^*,S_2^*,...,S_K^*\}$ that \underline{minimizes} the sum of the "distance" of each object and the centroid (the mean of the cluster that object is assigned to).
    \subitem Technically, we can write this as an optimization problem
    \begin{equation}
        \begin{aligned}
            \{S_1^*,S_2^*,...,S_K^*\}=\arg\min_{S_1,S_2,...,S_K}\sum_{k=1}^K\sum_{x\in S_k}\|x-\mu_k\|^2
        \end{aligned}
        \nonumber
    \end{equation}
\end{enumerate}








\end{document}