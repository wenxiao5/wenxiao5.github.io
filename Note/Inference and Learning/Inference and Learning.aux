\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global}
\pgfsyspdfmark {pgfid1}{28388828}{17982806}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Information-Theoretic Functional}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Learning Basics}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Parameters and Hyperparameters}{2}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural Network: Back Propagation Algorithm}{2}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Simple Neural Network\relax }}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{}{{2.1}{2}{Simple Neural Network\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Activations}{3}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Activations\relax }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{}{{2.2}{3}{Activations\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Multilayer Neural Network}{4}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Multilayer Neural Network\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{}{{2.3}{4}{Multilayer Neural Network\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}A Simple Example of Back Propagation Algorithm}{5}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Two Independent Pathways\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{}{{2.4}{6}{Two Independent Pathways\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Back Propagation Algorithm}{6}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Other Methods}{8}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Perceptron Algorithm}{8}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}General Idea}{8}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Perceptron Output\relax }}{8}{figure.caption.6}\protected@file@percent }
\newlabel{}{{2.5}{8}{Perceptron Output\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Perceptron\relax }}{9}{figure.caption.7}\protected@file@percent }
\newlabel{}{{2.6}{9}{Perceptron\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Algorithm}{9}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Limitations}{10}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}ADAptive LInear NEuron (ADALINE)}{10}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}General Idea}{10}{subsection.2.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces ADALINE\relax }}{10}{figure.caption.8}\protected@file@percent }
\newlabel{}{{2.7}{10}{ADALINE\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Widrow-Hoff Delta Rule}{11}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Logistic Regression (Binary-class Output)}{11}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Generative and Discriminative Classifiers}{11}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Sigmoid function}{12}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Cross-entropy Loss Function}{12}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Algorithm}{13}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Softmax Regression (Multi-class Output)}{13}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Multi-Class Classification and Multi-Label Classification}{13}{subsection.2.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Multi-Class Classification\relax }}{13}{figure.caption.9}\protected@file@percent }
\newlabel{}{{2.8}{13}{Multi-Class Classification\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Multi-Label Classification\relax }}{14}{figure.caption.10}\protected@file@percent }
\newlabel{}{{2.9}{14}{Multi-Label Classification\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Examples of Activation Layer and Loss Choice\relax }}{14}{figure.caption.11}\protected@file@percent }
\newlabel{}{{2.10}{14}{Examples of Activation Layer and Loss Choice\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}One-hot Encoding}{14}{subsection.2.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces One-hot encoding\relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{}{{2.11}{14}{One-hot encoding\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Softmax function}{15}{subsection.2.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Categorical Cross-entropy Loss Function}{16}{subsection.2.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Deep Feedforward Networks}{16}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Definition}{16}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Universal Approximation Theorem}{16}{subsection.2.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Deep Neural Network\relax }}{17}{figure.caption.13}\protected@file@percent }
\newlabel{}{{2.12}{17}{Deep Neural Network\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8} Mini-batch Optimization}{17}{section.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Stochastic Gradient Descent (SGD) and Batch Gradient Descent (BGD)}{17}{subsection.2.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Universal Approximation Theorem\relax }}{18}{figure.caption.14}\protected@file@percent }
\newlabel{}{{2.13}{18}{Universal Approximation Theorem\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces BGD and SGD\relax }}{18}{figure.caption.15}\protected@file@percent }
\newlabel{}{{2.14}{18}{BGD and SGD\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Mini-Batch Gradient Descent (MBGD)}{19}{subsection.2.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces SGD and MBGD\relax }}{19}{figure.caption.16}\protected@file@percent }
\newlabel{}{{2.15}{19}{SGD and MBGD\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Comparison of Approaches\relax }}{19}{figure.caption.17}\protected@file@percent }
\newlabel{}{{2.16}{19}{Comparison of Approaches\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Weight Initialization}{19}{section.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Xavier Initialization}{19}{subsection.2.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}He Activation}{20}{subsection.2.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Adaptive Optimization}{21}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Exponentially Weighted Moving Averages}{21}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Adaptive Learning Rates}{21}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Momentum}{21}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Root Mean Square Propagation (RMSProp)}{22}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Adaptive Moment Estimation (ADAM)}{22}{subsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Pseudocode of ADAM\relax }}{23}{figure.caption.18}\protected@file@percent }
\newlabel{}{{3.1}{23}{Pseudocode of ADAM\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Convolutional Neural Network (CNN)}{24}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Convolution and Cross-correlation}{24}{section.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Convolution Used in CNN (actually cross-correlation)\relax }}{24}{figure.caption.19}\protected@file@percent }
\newlabel{}{{4.1}{24}{Convolution Used in CNN (actually cross-correlation)\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Padding (cover the border)}{25}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Padding: $p=1$\relax }}{25}{figure.caption.20}\protected@file@percent }
\newlabel{}{{4.2}{25}{Padding: $p=1$\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Stride}{25}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Other Layer Types}{26}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Pooling}{26}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Example: maxpool\relax }}{26}{figure.caption.21}\protected@file@percent }
\newlabel{}{{4.3}{26}{Example: maxpool\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Unpooling}{26}{subsection.4.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Example: maxpool+unpool\relax }}{26}{figure.caption.22}\protected@file@percent }
\newlabel{}{{4.4}{26}{Example: maxpool+unpool\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}3D Convolution}{26}{section.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces 3D Convolution\relax }}{27}{figure.caption.23}\protected@file@percent }
\newlabel{}{{4.5}{27}{3D Convolution\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Generative model}{28}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Autoencoders}{28}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Basics}{28}{subsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Autoencoders\relax }}{28}{figure.caption.24}\protected@file@percent }
\newlabel{}{{5.1}{28}{Autoencoders\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}PCA and Autoencoders}{29}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Principal Component Analysis (PCA)\relax }}{29}{figure.caption.25}\protected@file@percent }
\newlabel{}{{5.2}{29}{Principal Component Analysis (PCA)\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Transposed Convolutions (upscale method)}{30}{subsection.5.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Transposed Convolutions\relax }}{30}{figure.caption.26}\protected@file@percent }
\newlabel{}{{5.3}{30}{Transposed Convolutions\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Comparison\relax }}{31}{figure.caption.27}\protected@file@percent }
\newlabel{}{{5.4}{31}{Comparison\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Transposed Convolution with Stride\relax }}{31}{figure.caption.28}\protected@file@percent }
\newlabel{}{{5.5}{31}{Transposed Convolution with Stride\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Statistical Inference}{32}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Basics}{32}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Decision Rule Examples}{32}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Maximum-Likelihood Principle (state is norandom)}{33}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Bayesian Decision Rule (state is random)}{34}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Rules}{34}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Maximum A Posteriori (MAP) Decision Rule (Binary example)}{35}{subsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Minimum Mean Squared Error (MMSE) Rule ($\mathbb  {R}^n$ example)}{35}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Comparison}{36}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Machine Learning in Inference}{37}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Empirical Risk Minimization (ERM)}{37}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Example: Linear MMSE (LMMSE) estimator}{37}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Penalized ERM}{38}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Stochastic Approximation}{39}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Stochastic Gradient Descent (SGD)}{41}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}SGD Application to Empirical Risk Minimization (ERM)}{42}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Different Gradient Descent for ERM}{43}{subsection.7.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Constraints on Learning Problem}{43}{subsection.7.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Stochastic Integration Methods}{45}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Deterministic Methods (Better in Low Dimension)}{45}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Riemann Integration}{45}{subsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Trapezoidal Rule}{45}{subsection.8.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces (a) Riemann approximation; (b) Trapezoidal approximation.\relax }}{45}{figure.caption.29}\protected@file@percent }
\newlabel{}{{8.1}{45}{(a) Riemann approximation; (b) Trapezoidal approximation.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Multidimensional Integration}{46}{subsection.8.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Two-dimensional integration using regular grid.\relax }}{46}{figure.caption.30}\protected@file@percent }
\newlabel{}{{8.2}{46}{Two-dimensional integration using regular grid.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Stachastic Methods (Better in High Dimension)}{46}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Classical Monte Carlo Integration}{46}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Importance Sampling}{47}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Bootstrap (not enough data)}{49}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Residual Bootstrap}{49}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Particle Filtering}{51}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Kalman Filtering (Linear Dynamic System)}{51}{section.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Particle Filtering (Nonlinear Dynamic System)}{51}{section.10.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Hidden Markov Model\relax }}{52}{figure.caption.31}\protected@file@percent }
\newlabel{}{{10.1}{52}{Hidden Markov Model\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Bayesian Recursive Filtering}{52}{subsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Particle Filter (bootstrap filter)}{52}{subsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}EM Algorithm}{54}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}General Structure of the EM Algorithm}{54}{section.11.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Complete and incomplete data spaces $Z$ and $Y$.\relax }}{55}{figure.caption.32}\protected@file@percent }
\newlabel{}{{11.1}{55}{Complete and incomplete data spaces $Z$ and $Y$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Example 1: Variance Estimation}{56}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Maximum-Likelihood (ML) Estimation}{56}{subsection.11.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.2}EM Algorithm}{56}{subsection.11.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Example 2: Estimation of Gaussian Mixtures}{57}{section.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}Unknown Means: ML estimation is hard}{57}{subsection.11.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.2}Unknown Means: EM Algorithm}{58}{subsection.11.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.3}Unknown Mixture Probabilities, Means and Variances}{59}{subsection.11.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Convergence of EM Algorithm}{59}{section.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.5}EM As an Alternating Maximization Algorithm}{60}{section.11.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Hidden Markov model (HMM)}{62}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Hidden Markov Model (HMM)\relax }}{62}{figure.caption.33}\protected@file@percent }
\newlabel{}{{12.1}{62}{Hidden Markov Model (HMM)\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Viterbi Algorithm: (MAP) estimate $X_{1:t}$ given $Y_{1:t}$}{62}{section.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.1}MAP estimation problem}{62}{subsection.12.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.2}Viterbi Algorithm}{63}{subsection.12.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces (a) Trellis diagram; (b)—(e) evolution of the Viterbi algorithm, showing surviving paths and values $V(t,x)$ at times $t = 2,3,4,5$; (f) optimal path $\vec  {x}^* = (0,2,0,2,0)$ and its value $\varepsilon (\vec  {x}^*) = 11$.\relax }}{63}{figure.caption.34}\protected@file@percent }
\newlabel{}{{12.2}{63}{(a) Trellis diagram; (b)—(e) evolution of the Viterbi algorithm, showing surviving paths and values $V(t,x)$ at times $t = 2,3,4,5$; (f) optimal path $\vec {x}^* = (0,2,0,2,0)$ and its value $\varepsilon (\vec {x}^*) = 11$.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Bayesian Estimation of a Sequence: Need (MMSE) estimate $X_{1:t}$ given $Y_{1:t}$}{64}{section.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Forward-Backward Algorithm: (MMSE) estimate $X_{1:t+1}$ given $Y_{1:t}$}{64}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.1}$\gamma _t(x) \triangleq \mathrm  {P}\left \{X_t=x \mid \vec  {Y}=\vec  {y}\right \}$}{64}{subsection.12.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.2}$\xi _t\left (x, x^{\prime }\right ) \triangleq \mathrm  {P}\left \{X_t=x, X_{t+1}=x^{\prime } \mid \vec  {Y}=\vec  {y}\right \}$}{66}{subsection.12.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.3}Scaling Factors}{66}{subsection.12.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Graphic Models}{67}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Graph Theory}{67}{section.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces (a) Directed and (b) Undirected graph.\relax }}{68}{figure.caption.35}\protected@file@percent }
\newlabel{}{{13.1}{68}{(a) Directed and (b) Undirected graph.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Bayesian Networks}{68}{section.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Markov Networks}{68}{section.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}General Form}{68}{subsection.13.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces (a) (b) Two Bayesian networks and (c) a Markov network.\relax }}{68}{figure.caption.36}\protected@file@percent }
\newlabel{}{{13.2}{68}{(a) (b) Two Bayesian networks and (c) a Markov network.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}Hammersley-Clifford theorem}{69}{subsection.13.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.3}Form of Gibbs distribution (Boltzmann distribution)}{69}{subsection.13.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Conversion of directed graph to undirected graph}{70}{section.13.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Graph moralization\relax }}{70}{figure.caption.37}\protected@file@percent }
\newlabel{}{{13.3}{70}{Graph moralization\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.5} Inference and Learning}{70}{section.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.1}Inference on Trees}{70}{subsection.13.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Example 1\relax }}{70}{figure.caption.38}\protected@file@percent }
\newlabel{}{{13.4}{70}{Example 1\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Belief propagation in a tree\relax }}{71}{figure.caption.39}\protected@file@percent }
\newlabel{}{{13.5}{71}{Belief propagation in a tree\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Variational Inference, Mean-Field Techniques}{73}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Naive Mean-Field Methods}{73}{section.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.1}Graphical Models}{74}{subsection.14.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.2}Ising Model}{74}{subsection.14.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Exponential Families of Probability Distributions}{76}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}ML Estimation}{78}{section.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Maximum Entropy}{78}{section.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.5}}{79}{section.14.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.6}Connection between Exponential Families and Graphic Models}{80}{section.14.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.1}Marginal polytope}{80}{subsection.14.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.2}Locally Consistent Marginal Distributions}{80}{subsection.14.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.3}Entropy on Tree Graphs}{82}{subsection.14.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.4}Naive Mean-Field Methods In Graph}{83}{subsection.14.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.5}Structural Mean Field Optimization}{83}{subsection.14.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.6}Bethe Entropy Approximation}{83}{subsection.14.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}$\ell _1$ Penalized Least Squares Minimization}{85}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Problem Statement}{85}{section.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Special Cases}{86}{section.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.1}Definition: Soft Threshold}{86}{subsection.15.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.2}Identity $A$}{86}{subsection.15.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.3}Orthonormal $A$}{86}{subsection.15.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.4}Quadratic Optimization ($\lambda =0$)}{86}{subsection.15.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}General Solution: Lasso}{87}{section.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.4}General Solution: Iterative Soft Thresholding Algorithm (ISTA)}{87}{section.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.1}Proximal Minimization Algorithm}{87}{subsection.15.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.2}Apply to $\ell _1$-penalized least-squares}{88}{subsection.15.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.5}Convergence Rate}{88}{section.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.6}Fast Iterative Soft Thresholding Algorithm (FISTA)}{89}{section.15.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.7}Alternating Direction Method of Multipliers (ADMM)}{89}{section.15.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Compressive Sensing}{91}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {16.1}Definitions related to Sparsity}{91}{section.16.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16.2}Measurement Matrix}{93}{section.16.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16.1}{\ignorespaces Measurement of sparse signal $\vec  {x}$ with support set $\Omega $ of size $k$.\relax }}{93}{figure.caption.40}\protected@file@percent }
\newlabel{}{{16.1}{93}{Measurement of sparse signal $\vec {x}$ with support set $\Omega $ of size $k$.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.2.1}Matrix Preliminaries}{93}{subsection.16.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.2.2}Recovery of k-Sparse Signals}{94}{subsection.16.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.2.3}Restricted Isometry Property}{95}{subsection.16.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16.3}Robust Signal Recovery from Noiseless Observations}{95}{section.16.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16.2}{\ignorespaces $\ell _1$ recovery for $n=2$ and $m=1$\relax }}{96}{figure.caption.41}\protected@file@percent }
\newlabel{}{{16.2}{96}{$\ell _1$ recovery for $n=2$ and $m=1$\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.4}Robust Signal Recovery from Noisy Observations}{97}{section.16.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.4.1}Bounded Noise}{97}{subsection.16.4.1}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{nobblfile}
\gdef \@abspage@last{104}
