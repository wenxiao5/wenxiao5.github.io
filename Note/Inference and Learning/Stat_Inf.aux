\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{nty/global//global/global}
\HyPL@Entry{0<</S/A>>}
\pgfsyspdfmark {pgfid1}{28388830}{16767252}
\HyPL@Entry{1<</S/r>>}
\HyPL@Entry{8<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Information-Theoretic Functional}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Definitions}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Entropy}{1}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Kullback-Leibler Divergence}{1}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Cross-Entropy}{2}{subsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Mutual Information}{2}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Statistics Basics}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Random Sampling}{3}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Sample Mean and Sample Variance}{4}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Distributional Properties}{4}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Order Statistics}{4}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Statistics Model (ECON 240B)}{6}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Model}{6}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Parametric Model}{6}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Parameter}{6}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Model Estimation (ECON 240B)}{7}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Plug-In Estimation}{7}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Bootstrap}{9}{subsection.2.3.2}\protected@file@percent }
\newlabel{consistency}{{{*}}{10}{}{AMS.2}{}}
\newlabel{ex:inconsistency1}{{2.8}{12}{}{exam.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Point Estimation}{14}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Method of Moments (MM)}{14}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Maximum Likelihood (ML)}{16}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Comparing Estimators: Mean Squared Error}{17}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Sufficient Statistic}{18}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Minimal Sufficient Statistic}{20}{subsection.2.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Complete Statistic}{21}{subsection.2.4.6}\protected@file@percent }
\newlabel{comp_exp_fam}{{2.9}{22}{Complete Statistic}{tcb@cnt@theorem.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.7}Cram√©r-Rao Lower Bound}{22}{subsection.2.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Hypothesis Testing}{24}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Formulation of Testing Problem}{24}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Errors, Power Function, and Agenda}{25}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Choice of Critical Value}{26}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Choice of Test Statistic: Uniformly Most Powerful (UMP) Level $\alpha $ Test}{27}{subsection.2.5.4}\protected@file@percent }
\newlabel{NP_lemma}{{2.11}{27}{Choice of Test Statistic: Uniformly Most Powerful (UMP) Level $\alpha $ Test}{tcb@cnt@theorem.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Generalized Neyman-Pearson Lemma}{29}{subsection.2.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Trinity of Classical Tests}{29}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Test Statistics}{30}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Approximation to $T_{LR}$}{31}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Interval Estimation}{31}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Decision Rule Based Statistical Inference}{33}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Decision Rule}{33}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Maximum-Likelihood Principle (state is norandom)}{33}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bayesian Decision Rule (state is random)}{34}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Rules}{34}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Optimization Problem in Bayes Form}{35}{subsection.3.3.2}\protected@file@percent }
\newlabel{ex:square_loss}{{3.4}{36}{Optimization Problem in Bayes Form}{exam.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Maximum A Posteriori (MAP) Decision Rule (Binary example)}{37}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Minimum Mean Squared Error (MMSE) Rule ($\mathbb  {R}^n$ example)}{37}{subsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Comparison}{38}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Bootstrap}{39}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Traditional Monte-Carlo Approach}{39}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Bootstrap (When data is not enough)}{40}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Residual Bootstrap (for problem with not i.i.d. data)}{40}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Example: Linear}{41}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Example: Nonlinear Markov Process}{41}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Posterior Simulation / Bayesian (Weighted) Bootstrap}{42}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Dirichlet Distribution Prior}{42}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Dirichlet Distribution Examples}}{43}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{}{{4.1}{43}{Dirichlet Distribution Examples}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Haldane Prior}{43}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Linear Model Case}{43}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Bernoulli Case}{44}{subsection.4.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Nonparameteric Prediction Probelm}{45}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{SSR}{{{SSR}}{45}{}{AMS.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}$K$-normal Means Probelm}{46}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Assumptions}{46}{subsection.5.1.1}\protected@file@percent }
\newlabel{GSO}{{5.1}{46}{Assumptions}{tcb@cnt@definition.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Maximum Likelihood Estimator}{47}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Risk of MLE}{47}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}James-Stein Type Estimator}{48}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4.1}Stein's Unbiased Risk Estimate (SURE)}{48}{subsubsection.5.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4.2}James and Stein Estimator}{49}{subsubsection.5.1.4.2}\protected@file@percent }
\newlabel{RJS}{{{RJS}}{50}{James and Stein Estimator}{AMS.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4.3}A more general form of estimator $\mathcal  {L}=\{C \mathbf  {Z}:C=\text  {diag}\vec  {c},\vec  {c}\in [0,1]^K\}$}{50}{subsubsection.5.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Linear Predictors / Regression}{51}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Best Linear Predictor}{51}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Convergence of OLS}{52}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Approximation}{52}{subsection.6.2.1}\protected@file@percent }
\newlabel{CLT}{{6.2}{53}{Approximation}{tcb@cnt@theorem.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Testing and Confidence Interval}{54}{subsection.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Long, Short, Auxilary Regression}{54}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Residual Regression}{56}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Card-Krueger Model}{57}{section.6.5}\protected@file@percent }
\newlabel{LR}{{{LR}}{57}{Card-Krueger Model}{AMS.6}{}}
\newlabel{AR}{{{AR}}{57}{Card-Krueger Model}{AMS.7}{}}
\newlabel{AR-1}{{{AR-1}}{58}{Card-Krueger Model}{AMS.8}{}}
\newlabel{SR}{{{SR}}{58}{Card-Krueger Model}{AMS.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Proxy Variable Regression}{58}{subsection.6.5.1}\protected@file@percent }
\newlabel{PVR}{{{PVR}}{58}{Proxy Variable Regression}{AMS.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Instrumental Variables}{59}{section.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Motivation}{59}{subsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}I.V. Model}{59}{subsection.6.6.2}\protected@file@percent }
\newlabel{hG}{{6.1}{61}{}{equation.6.6.1}{}}
\newlabel{hl}{{{hl}}{61}{}{AMS.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Weak I.V.}{61}{subsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Linear Generalized Method of Moments (Linear GMM)}{62}{section.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.1}Generalized Method of Moments (GMM)}{62}{subsection.6.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.2}Linear GMM}{63}{subsection.6.7.2}\protected@file@percent }
\newlabel{GMM_est}{{6.1}{63}{Linear GMM}{equation.6.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.3}Properties of Linear GMM Estimator}{64}{subsection.6.7.3}\protected@file@percent }
\newlabel{hat_beta_minus_beta}{{6.2}{64}{Properties of Linear GMM Estimator}{equation.6.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.4}Alternative: Continuous Updating Estimator}{65}{subsection.6.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.5}Inference}{65}{subsection.6.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.6}OVER-ID Test}{66}{subsection.6.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.7}Bootstrap GMM}{68}{subsection.6.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Panel Data Models}{68}{section.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8.1}Pooled OLS}{69}{subsection.6.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8.2}Fixed Effect Model}{70}{subsection.6.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8.3}Random Effect Model}{71}{subsection.6.8.3}\protected@file@percent }
\newlabel{1}{{6.3}{71}{Random Effect Model}{equation.6.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8.4}Two-Way Fixed Effect Model}{72}{subsection.6.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8.5}Arellano Bond Approach}{73}{subsection.6.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Control Function Approach (another approach to handle endogenieity)}{74}{section.6.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.10}LATE (Local ATE): Application of I.V. on Potential Outcomes}{74}{section.6.10}\protected@file@percent }
\newlabel{ass:LATE}{{6.10}{75}{LATE (Local ATE): Application of I.V. on Potential Outcomes}{Item.241}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.11}Difference in Difference (DiD)}{76}{section.6.11}\protected@file@percent }
\newlabel{ass:DiD}{{6.11}{76}{Difference in Difference (DiD)}{equation.6.11.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.1}After OLS Regression}{77}{subsection.6.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.2}Difference in Difference}{77}{subsection.6.11.2}\protected@file@percent }
\newlabel{DiD}{{{DiD}}{77}{}{AMS.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.12}Extremum Estimation, M-Estimation}{78}{section.6.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12.1}Definitions}{78}{subsection.6.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12.2}Consistency of M-estimators}{79}{subsection.6.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.12.3}Asymptotic Normality of M-estimators}{80}{subsection.6.12.3}\protected@file@percent }
\newlabel{thm:asymptotic_normality_of_m_estimators}{{6.15}{80}{Asymptotic Normality of M-estimators}{tcb@cnt@theorem.6.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.13}Binary Choice}{81}{section.6.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.1}Latent Utility Models}{82}{subsection.6.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.2}Estimation}{82}{subsection.6.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.3}Consistency}{83}{subsection.6.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.4}Asymptotic Normality of $\hat  {\beta }_{MLE}$}{84}{subsection.6.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Machine Learning in Inference}{86}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Empirical Risk Minimization (ERM)}{86}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Example: Linear MMSE (LMMSE) estimator}{86}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Penalized ERM}{87}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Stochastic Approximation}{88}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Stochastic Gradient Descent (SGD)}{90}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}SGD Application to Empirical Risk Minimization (ERM)}{91}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Different Gradient Descent for ERM}{92}{subsection.7.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Constraints on Learning Problem}{92}{subsection.7.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Stochastic Integration Methods}{94}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Deterministic Methods (Better in Low Dimension)}{94}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Riemann Integration}{94}{subsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Trapezoidal Rule}{94}{subsection.8.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces (a) Riemann approximation; (b) Trapezoidal approximation.}}{94}{figure.caption.14}\protected@file@percent }
\newlabel{}{{8.1}{94}{(a) Riemann approximation; (b) Trapezoidal approximation}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Multidimensional Integration}{95}{subsection.8.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Two-dimensional integration using regular grid.}}{95}{figure.caption.15}\protected@file@percent }
\newlabel{}{{8.2}{95}{Two-dimensional integration using regular grid}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Stochastic Methods (Better in High Dimension)}{95}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Classical Monte Carlo Integration}{95}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Importance Sampling}{96}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Particle Filtering}{98}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Kalman Filtering (Linear Dynamic System)}{98}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Particle Filtering (Nonlinear Dynamic System)}{98}{section.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Hidden Markov Model}}{99}{figure.caption.16}\protected@file@percent }
\newlabel{}{{9.1}{99}{Hidden Markov Model}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Bayesian Recursive Filtering}{99}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Particle Filter (bootstrap filter)}{99}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {10}EM Algorithm}{101}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}General Structure of the EM Algorithm}{101}{section.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Complete and incomplete data spaces $Z$ and $Y$.}}{102}{figure.caption.20}\protected@file@percent }
\newlabel{}{{10.1}{102}{Complete and incomplete data spaces $Z$ and $Y$}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Example 1: Variance Estimation}{103}{section.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}Maximum-Likelihood (ML) Estimation}{103}{subsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}EM Algorithm}{103}{subsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Example 2: Estimation of Gaussian Mixtures}{104}{section.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.1}Unknown Means: ML estimation is hard}{104}{subsection.10.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.2}Unknown Means: EM Algorithm}{105}{subsection.10.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3.3}Unknown Mixture Probabilities, Means and Variances}{106}{subsection.10.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Convergence of EM Algorithm}{106}{section.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.5}EM As an Alternating Maximization Algorithm}{107}{section.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Hidden Markov model (HMM)}{109}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Hidden Markov Model (HMM)}}{109}{figure.caption.22}\protected@file@percent }
\newlabel{}{{11.1}{109}{Hidden Markov Model (HMM)}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Viterbi Algorithm: (MAP) estimate $X_{1:t}$ given $Y_{1:t}$}{109}{section.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.1}MAP estimation problem}{109}{subsection.11.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.2}Viterbi Algorithm}{110}{subsection.11.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces (a) Trellis diagram; (b)‚Äî(e) evolution of the Viterbi algorithm, showing surviving paths and values $V(t,x)$ at times $t = 2,3,4,5$; (f) optimal path $\vec  {x}^* = (0,2,0,2,0)$ and its value $\varepsilon (\vec  {x}^*) = 11$.}}{110}{figure.caption.23}\protected@file@percent }
\newlabel{}{{11.2}{110}{(a) Trellis diagram; (b)‚Äî(e) evolution of the Viterbi algorithm, showing surviving paths and values $V(t,x)$ at times $t = 2,3,4,5$; (f) optimal path $\vec {x}^* = (0,2,0,2,0)$ and its value $\varepsilon (\vec {x}^*) = 11$}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Bayesian Estimation of a Sequence: Need (MMSE) estimate $X_{1:t}$ given $Y_{1:t}$}{111}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Forward-Backward Algorithm: (MMSE) estimate $X_{1:t+1}$ given $Y_{1:t}$}{111}{section.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}$\gamma _t(x) \triangleq \mathrm  {P}\left \{X_t=x \mid \vec  {Y}=\vec  {y}\right \}$}{111}{subsection.11.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.2}$\xi _t\left (x, x^{\prime }\right ) \triangleq \mathrm  {P}\left \{X_t=x, X_{t+1}=x^{\prime } \mid \vec  {Y}=\vec  {y}\right \}$}{113}{subsection.11.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.3}Scaling Factors}{113}{subsection.11.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Graphic Models}{114}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Graph Theory}{114}{section.12.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces (a) Directed and (b) Undirected graph.}}{115}{figure.caption.24}\protected@file@percent }
\newlabel{}{{12.1}{115}{(a) Directed and (b) Undirected graph}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Bayesian Networks}{115}{section.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Markov Networks}{115}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.1}General Form}{115}{subsection.12.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces (a) (b) Two Bayesian networks and (c) a Markov network.}}{115}{figure.caption.25}\protected@file@percent }
\newlabel{}{{12.2}{115}{(a) (b) Two Bayesian networks and (c) a Markov network}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.2}Hammersley-Clifford theorem}{116}{subsection.12.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3.3}Form of Gibbs distribution (Boltzmann distribution)}{116}{subsection.12.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Conversion of directed graph to undirected graph}{117}{section.12.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces Graph moralization}}{117}{figure.caption.26}\protected@file@percent }
\newlabel{}{{12.3}{117}{Graph moralization}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5} Inference and Learning}{117}{section.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.1}Inference on Trees}{117}{subsection.12.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Example 1}}{117}{figure.caption.27}\protected@file@percent }
\newlabel{}{{12.4}{117}{Example 1}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Belief propagation in a tree}}{118}{figure.caption.28}\protected@file@percent }
\newlabel{}{{12.5}{118}{Belief propagation in a tree}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Variational Inference, Mean-Field Techniques}{120}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Naive Mean-Field Methods}{120}{section.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.1}Graphical Models}{121}{subsection.13.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.2}Ising Model}{121}{subsection.13.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Exponential Families of Probability Distributions}{123}{section.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.3}ML Estimation}{125}{section.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Maximum Entropy}{125}{section.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.5}}{126}{section.13.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13.6}Connection between Exponential Families and Graphic Models}{127}{section.13.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.1}Marginal polytope}{127}{subsection.13.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.2}Locally Consistent Marginal Distributions}{127}{subsection.13.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.3}Entropy on Tree Graphs}{129}{subsection.13.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.4}Naive Mean-Field Methods In Graph}{130}{subsection.13.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.5}Structural Mean Field Optimization}{130}{subsection.13.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.6.6}Bethe Entropy Approximation}{130}{subsection.13.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {14}$\ell _1$ Penalized Least Squares Minimization}{132}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Problem Statement}{132}{section.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Special Cases}{133}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.1}Definition: Soft Threshold}{133}{subsection.14.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.2}Identity $A$}{133}{subsection.14.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.3}Orthonormal $A$}{133}{subsection.14.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.4}Quadratic Optimization ($\lambda =0$)}{133}{subsection.14.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}General Solution: Lasso}{134}{section.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.4}General Solution: Iterative Soft Thresholding Algorithm (ISTA)}{134}{section.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.1}Proximal Minimization Algorithm}{134}{subsection.14.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.2}Apply to $\ell _1$-penalized least-squares}{135}{subsection.14.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Convergence Rate}{135}{section.14.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.6}Fast Iterative Soft Thresholding Algorithm (FISTA)}{136}{section.14.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.7}Alternating Direction Method of Multipliers (ADMM)}{136}{section.14.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Compressive Sensing}{138}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Definitions related to Sparsity}{138}{section.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Measurement Matrix}{140}{section.15.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces Measurement of sparse signal $\vec  {x}$ with support set $\Omega $ of size $k$.}}{140}{figure.caption.29}\protected@file@percent }
\newlabel{}{{15.1}{140}{Measurement of sparse signal $\vec {x}$ with support set $\Omega $ of size $k$}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.1}Matrix Preliminaries}{140}{subsection.15.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.2}Recovery of k-Sparse Signals}{141}{subsection.15.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.3}Restricted Isometry Property}{142}{subsection.15.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Robust Signal Recovery from Noiseless Observations}{142}{section.15.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces $\ell _1$ recovery for $n=2$ and $m=1$}}{143}{figure.caption.30}\protected@file@percent }
\newlabel{}{{15.2}{143}{$\ell _1$ recovery for $n=2$ and $m=1$}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.4}Robust Signal Recovery from Noisy Observations}{144}{section.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4.1}Bounded Noise}{144}{subsection.15.4.1}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{nobblfile}
\gdef \@abspage@last{152}
