\contentsline {chapter}{\numberline {1}Field and Vector Space}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Field $(\mathbb {F},+,\cdot )$}{1}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Definition of Field \small {(@ Lec 02 of ECON 204)}}{1}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}Vector Space}{1}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Definition of Vector Space \small {(@ Lec 02 of ECON 204)}}{1}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Theorem: A field is a vector space over its subfield}{2}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Vector Subspace}{2}{subsection.1.2.3}%
\contentsline {subsection}{\numberline {1.2.4}Linear Independent}{2}{subsection.1.2.4}%
\contentsline {subsection}{\numberline {1.2.5}span V, basis, dimension}{2}{subsection.1.2.5}%
\contentsline {subsection}{\numberline {1.2.6}Dimension}{3}{subsection.1.2.6}%
\contentsline {subsection}{\numberline {1.2.7}Theorem: $|V|>\dim X \Rightarrow $ linearly dependent}{3}{subsection.1.2.7}%
\contentsline {subsection}{\numberline {1.2.8}Theorem: $|V|=n$: Linear Indep $\Leftrightarrow $ Spans $\Rightarrow $ Basis}{4}{subsection.1.2.8}%
\contentsline {subsection}{\numberline {1.2.9}Standard basis vectors}{4}{subsection.1.2.9}%
\contentsline {section}{\numberline {1.3}Linear Transformation}{4}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Definition of Linear Transformation}{4}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Composition of Linear Transformations is also Linear}{4}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Function from a Basis extends uniquely to a Linear Transformation}{4}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Image, Kernel, Rank}{5}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}The Rank-Nullity Theorem: $\dim X=\dim \textnormal {ker }T+\textnormal {Rank }T$}{5}{subsection.1.3.5}%
\contentsline {subsection}{\numberline {1.3.6}Theorem: Linear Transformation $T$ is 1-to-1 $\Leftrightarrow $ $\textnormal {ker }T = \{0\}$}{5}{subsection.1.3.6}%
\contentsline {subsection}{\numberline {1.3.7}Definition of Invertible Linear Transformation}{5}{subsection.1.3.7}%
\contentsline {subsection}{\numberline {1.3.8}Theorem: Inverse of a Linear Transformation is also Linear}{5}{subsection.1.3.8}%
\contentsline {subsection}{\numberline {1.3.9}Theorem: Linear Transformation is completely determined by values on basis}{6}{subsection.1.3.9}%
\contentsline {subsection}{\numberline {1.3.10}GL(V): set of invertible linear transformations $V \rightarrow V$}{6}{subsection.1.3.10}%
\contentsline {section}{\numberline {1.4}Isomorphism}{6}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Isomorphic: $\exists $ invertible $T \in L(X, Y)$}{6}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Theorem: Isomorphic $\Leftrightarrow $ $\dim X = \dim Y$}{6}{subsection.1.4.2}%
\contentsline {section}{\numberline {1.5}Quotient Vector Spaces}{7}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Quotient Vector Space: $X/W$}{7}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Theorem: $\dim (X/W)=\dim X - \dim W$}{7}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}Theorem: $T$ is isomorphic to $X/\textnormal {ker }T$}{7}{subsection.1.5.3}%
\contentsline {chapter}{\numberline {2}Matrix}{8}{chapter.2}%
\contentsline {section}{\numberline {2.1}Coordinate Representation}{8}{section.2.1}%
\contentsline {section}{\numberline {2.2}Matrix Representation of a Linear Transformation}{8}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Definition: matrix corresponds to a linear transformation}{8}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Theorem: Matrix Space $\cong $ Linear Transformation Space}{9}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Theorem: $\textnormal {Mtx}_{W,V}(T)\cdot \textnormal {Mtx}_{V,U}(S)=\textnormal {Mtx}_{W,U}(T\circ S)$}{10}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Change of Basis and Similarity}{10}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Change of Basis}{10}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Similarity}{11}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Theorem: Similar Matrices $\Leftrightarrow $ Same Linear Transformation for Two Bases}{11}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Square Matrix $A_{n\times n}$: $det(A)$, singular}{12}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Determinant $det(A)$}{12}{subsection.2.4.1}%
\contentsline {section}{\numberline {2.5}Eigenvalues and Eigenvectors}{12}{section.2.5}%
\contentsline {section}{\numberline {2.6}Diagonalizable Matrix}{12}{section.2.6}%
\contentsline {section}{\numberline {2.7}Orthogonal, Orthonormal, Unitary}{14}{section.2.7}%
\contentsline {section}{\numberline {2.8}Eigen Decomposition of Symmetric Matrices Results}{15}{section.2.8}%
\contentsline {section}{\numberline {2.9}Diagonalization of Real Symmetric Matrices}{15}{section.2.9}%
\contentsline {subsection}{\numberline {2.9.1}Proposition: $\lambda _{\min }\|x\|^2\leq x^TAx\leq \lambda _{\max }\|x\|^2$}{16}{subsection.2.9.1}%
\contentsline {subsection}{\numberline {2.9.2}Proposition: $\lambda ^2$ is the eigenvalue of $A^2$ and $A^TA$}{16}{subsection.2.9.2}%
\contentsline {section}{\numberline {2.10}Trace}{17}{section.2.10}%
\contentsline {section}{\numberline {2.11}Jacobian matrix}{17}{section.2.11}%
\contentsline {section}{\numberline {2.12}Hessian matrix}{17}{section.2.12}%
\contentsline {section}{\numberline {2.13}Positive Definite Matrices}{18}{section.2.13}%
\contentsline {subsection}{\numberline {2.13.1}Definition}{18}{subsection.2.13.1}%
\contentsline {subsection}{\numberline {2.13.2}Condition number (for PD matrix)}{18}{subsection.2.13.2}%
\contentsline {subsection}{\numberline {2.13.3}Diagonal matrix situation}{18}{subsection.2.13.3}%
\contentsline {subsection}{\numberline {2.13.4}Using eigenvalues}{19}{subsection.2.13.4}%
\contentsline {subsection}{\numberline {2.13.5}Sylvesterâ€™s Criterion}{19}{subsection.2.13.5}%
\contentsline {subsection}{\numberline {2.13.6}Cholesky Decomposition: $A=LL^T$}{21}{subsection.2.13.6}%
\contentsline {chapter}{\numberline {3}Linear Maps between Normed Spaces}{22}{chapter.3}%
\contentsline {chapter}{\numberline {4}Euclidean geometry basics}{25}{chapter.4}%
\contentsline {section}{\numberline {4.1}Metrics}{25}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Vector's Norm}{25}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Matrix's Norm}{25}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Spectral Radius}{26}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Euclidean distance, inner product}{27}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2}Inequalities}{28}{section.4.2}%
\contentsline {section}{\numberline {4.3}General Inner Products}{28}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1} Inner Product}{28}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Theorem: $*$ is inner product iff $\vec {x}*\vec {y}=\vec {x}^T H \vec {y}$ for some symmetric $H$}{29}{subsection.4.3.2}%
\contentsline {section}{\numberline {4.4}Isometry}{29}{section.4.4}%
\contentsline {section}{\numberline {4.5} Linear isometries i.e. orthogonal group}{30}{section.4.5}%
\contentsline {section}{\numberline {4.6}Special orthogonal group}{30}{section.4.6}%
\contentsline {section}{\numberline {4.7}Translation}{30}{section.4.7}%
\contentsline {section}{\numberline {4.8}All isometries can be represented by a composition of \textit {a translation} and \textit {an orthogonal transformation}}{31}{section.4.8}%
\contentsline {chapter}{\numberline {5}Algebra Computation}{32}{chapter.5}%
\contentsline {section}{\numberline {5.1}Hessian Matrix}{32}{section.5.1}%
\contentsline {section}{\numberline {5.2}Taylor's Expansion}{32}{section.5.2}%
\contentsline {section}{\numberline {5.3} Random Vectors and Random Matrices}{32}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Mean}{32}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Variance, Covariance}{33}{subsection.5.3.2}%
\contentsline {section}{\numberline {5.4} Matrix Multiplication}{34}{section.5.4}%
\contentsline {section}{\numberline {5.5}Matrix Derivation}{34}{section.5.5}%
\contentsline {section}{\numberline {5.6}Inverse Matrix}{36}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Block Matrix Determinant}{37}{subsection.5.6.1}%
\contentsline {section}{\numberline {5.7}Linear Regression: Least Square}{37}{section.5.7}%
\contentsline {subsection}{\numberline {5.7.1}Normal Equations}{37}{subsection.5.7.1}%
\contentsline {chapter}{\numberline {6}Matrix Decomposition}{38}{chapter.6}%
\contentsline {section}{\numberline {6.1}Cholesky Decomposition}{38}{section.6.1}%
\contentsline {section}{\numberline {6.2}LU Decomposition (Restricted to Square)}{38}{section.6.2}%
\contentsline {section}{\numberline {6.3}SVD: Singular Value Decomposition}{39}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Pseudo-inverse}{39}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Analysis of $A^TA$ and $AA^T$}{40}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Solve Normal Equations}{40}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Low-Rank Approximation}{40}{subsection.6.3.4}%
